{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow | Zero to Master course.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Lv054KIHvzgU",
        "dXcD4hgs1xeB",
        "QXlRD2o3YqkR",
        "gvnZBzA7ZMCX",
        "KebMK_HHb78_",
        "j_DzG1V3hYu8"
      ],
      "mount_file_id": "1MxCsT1QosIMRYouox6rmQoHq6-n4ru6X",
      "authorship_tag": "ABX9TyM71YR0+ufbH/fqSooFg2Y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adlihs/tensorflow/blob/main/TensorFlow_%7C_Zero_to_Master_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF Fundamentals"
      ],
      "metadata": {
        "id": "lsunAVB1mgjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJesnjiFmDJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaaa562-90a2-460f-930f-a95deab034c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors with tf.constant()\n",
        "scalar = tf.constant(7)\n",
        "scalar"
      ],
      "metadata": {
        "id": "aHrF4mKVnarF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e39708-1a01-4c27-b65d-a9cff18cad84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the number of dimension of a tensor (ndim stands for number of dimension)\n",
        "scalar.ndim"
      ],
      "metadata": {
        "id": "x9zgFTyaoGIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb233c7-5cff-412f-a80d-7b26c8219c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vector\n",
        "vector = tf.constant([10,10])\n",
        "vector"
      ],
      "metadata": {
        "id": "WAQpMT9RoNuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d11adf7-ade4-4d86-e866-ec1a9d8ec09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of our vector\n",
        "vector.ndim"
      ],
      "metadata": {
        "id": "JvaCxc1Yoc7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cf0696-31e0-41a2-d2c6-315b97228f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix (has more than 1 dimension)\n",
        "matrix = tf.constant([ [10,7],\n",
        "                      [7,10]])\n",
        "\n",
        "matrix"
      ],
      "metadata": {
        "id": "3m8l4Xxjoi1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24aaab6c-e0f1-401e-9259-61ecfa35e26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 7, 10]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "id": "lmTXyPLNo9IJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf43f6d-f37f-4ff9-a4ca-6c29c1771a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cretae another matrix\n",
        "matrix_2 = tf.constant([[10.,7.],\n",
        "                        [3.,2.],\n",
        "                        [8.,9.]], dtype=tf.float16) #specifiy the data type\n",
        "matrix_2"
      ],
      "metadata": {
        "id": "z79AQeoKpLsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afb8fbe-179f-4b56-c447-d2aeacfb89cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
              "array([[10.,  7.],\n",
              "       [ 3.,  2.],\n",
              "       [ 8.,  9.]], dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_2.ndim"
      ],
      "metadata": {
        "id": "JMs6CInTp4FU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e013714-276e-4d63-8519-33b7a01ed49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = tf.constant([[[1,2,3,],\n",
        "                       [4,5,6]],\n",
        "                      [[7,8,9],\n",
        "                       [10,11,12]],\n",
        "                      [[13,14,15],\n",
        "                       [16,17,18]]]) # [[0,0,0],[0,0,0]]\n",
        "                                     # [[0,0,0],[0,0,0]]\n",
        "                                     # [[0,0,0],[0,0,0]]\n",
        "tensor"
      ],
      "metadata": {
        "id": "Szi9ywCvqExL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c01e2a-ce12-412c-dda9-64d68be6e5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3],\n",
              "        [ 4,  5,  6]],\n",
              "\n",
              "       [[ 7,  8,  9],\n",
              "        [10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15],\n",
              "        [16, 17, 18]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.ndim"
      ],
      "metadata": {
        "id": "L46wTvsnr_5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51341ad8-64fa-48c6-a219-54868462b96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar: Single number\n",
        "# Vector: a number with direction (e.g wind speed and direction)\n",
        "# Matrix: a 2-dimensional array of numbers\n",
        "# Tensor: an n-dimensional array of number (when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)"
      ],
      "metadata": {
        "id": "X3pDj7nvsILr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors with `tf.Variable`"
      ],
      "metadata": {
        "id": "v7L9Wetqtog1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "changeable_tensor = tf.Variable([10,7])\n",
        "unchangeable_tensor = tf.constant([10,7])\n",
        "changeable_tensor, unchangeable_tensor"
      ],
      "metadata": {
        "id": "hvhrOIDMtnn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399445ff-c6b8-4ed8-eff6-150e30d2d2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change on of the elements\n",
        "\n",
        "changeable_tensor[0] = 7\n",
        "changeable_tensor"
      ],
      "metadata": {
        "id": "aIJ6fB2HulPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "49fac83d-6d6e-44c5-a97b-0a51b4a8deb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-294cdbe4efc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change on of the elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchangeable_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mchangeable_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using .assign()\n",
        "changeable_tensor[0].assign(7)\n",
        "changeable_tensor"
      ],
      "metadata": {
        "id": "iqYarP90u0F9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce45eb3-0057-4122-9788-f7fe6a4c13bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try to change the unchangeable tensor\n",
        "\n",
        "unchangeable_tensor[0].assign(7)\n",
        "#'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
      ],
      "metadata": {
        "id": "tQtgQgUKvBha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "7d014618-e30f-4940-f659-dbeb225425b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ba0a202ced1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try to change the unchangeable tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munchangeable_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating random tensors\n",
        "Random tensors are tensors of some arbitrary size wich contain random numbers"
      ],
      "metadata": {
        "id": "Lv054KIHvzgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 random tensor (but the same)\n",
        "random_1 = tf.random.Generator.from_seed(42) # set seed for reproducitibility\n",
        "random_1 = random_1.normal(shape=(3,2))\n",
        "random_2 = tf.random.Generator.from_seed(42)\n",
        "random_2 = random_2.normal(shape=(3,2))\n",
        "\n",
        "#Are they equal?\n",
        "random_1, random_2, random_1 == random_2"
      ],
      "metadata": {
        "id": "1fNHcmfZvvI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af84a526-0a58-4f4b-a2a1-43dccee8cdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[ True,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shuffle the oreder of elements in the tensor"
      ],
      "metadata": {
        "id": "dXcD4hgs1xeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle a tensor | Valueble for when you want to shuffle your data so the inherent order does not effect learning\n",
        "not_shuffle = tf.constant([[10,7],\n",
        "                           [3,4],\n",
        "                           [2,5]])\n",
        "not_shuffle.ndim"
      ],
      "metadata": {
        "id": "7fyQEc5z0uG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7453b32f-07f7-4471-c97c-e19c3e186369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_shuffle"
      ],
      "metadata": {
        "id": "AmcPYeHMQilc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a8e0e7-4315-4ca2-b3f4-bb3016e72907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4],\n",
              "       [ 2,  5]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle our non-shuffled tensor\n",
        "\n",
        "tf.random.shuffle(not_shuffle)"
      ],
      "metadata": {
        "id": "Lmbr9gDaRAXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26174c2-5d7b-4b2b-a2e3-c65fb2a0ea58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 2,  5],\n",
              "       [10,  7],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it looks if we want our shuffled tensors to be in the same oreder we have got to use the global level random seed as well as the operation level random seed\n",
        "tf.random.set_seed(55) #global level random seed\n",
        "tf.random.shuffle(not_shuffle, seed=55) #operation level random seed"
      ],
      "metadata": {
        "id": "_vMw3w5RRmBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc1f00e-59e9-4c1a-d4ab-deafaecd80c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 2,  5],\n",
              "       [10,  7],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other way to make tensors"
      ],
      "metadata": {
        "id": "QXlRD2o3YqkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor of all ones\n",
        "tf.ones([10,7])\n"
      ],
      "metadata": {
        "id": "Vb29nwO-WFD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef90ea8-c363-4b5c-8e74-659aa4fd9b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor of all zeros\n",
        "tf.zeros(shape=(3,4))"
      ],
      "metadata": {
        "id": "kb-mOsF4Y673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aff258a-72f8-40cd-8062-210502ce0ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn Numpy arrays into tensors\n",
        "The main difference between Numpy arrays and Tensorflow tensors is that tensors can be run on a GPU computing"
      ],
      "metadata": {
        "id": "gvnZBzA7ZMCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn Numpy arrays into tensors\n",
        "import numpy as np\n",
        "numpy_A = np.arange(1,25,dtype=np.int32) #numpy Arrays\n",
        "numpy_A\n",
        "\n",
        "#X = tf.constant(some_matrix)  #capital letter for matrix or tensor\n",
        "#y = tf.constant(vector) #non-capital letter for vector"
      ],
      "metadata": {
        "id": "HNlbEDbtZF2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be5cec4-449f-4502-e407-0c45366f3673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert numpy to tensor\n",
        "A = tf.constant(numpy_A, shape=(3,8))\n",
        "B = tf.constant(numpy_A)\n",
        "A,B"
      ],
      "metadata": {
        "id": "3FV1UrRSaUX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e35182f-c885-482b-88f2-0c43f1a83d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
              " array([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
              "        [17, 18, 19, 20, 21, 22, 23, 24]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
              " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.ndim"
      ],
      "metadata": {
        "id": "LNWkiezObfBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830474d7-4ad7-4345-ee81-4b64d714e4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting information from Tensors\n",
        "* Shape\n",
        "* Rank\n",
        "* axis or dimension\n",
        "* Size"
      ],
      "metadata": {
        "id": "KebMK_HHb78_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a rank 4 tensor (4 dimensions)\n",
        "rank_4_tensor = tf.zeros(shape=[2,3,4,5])\n",
        "rank_4_tensor\n"
      ],
      "metadata": {
        "id": "dKcfZyR8bQzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62e1a68-7af1-4ea0-de6f-b3618f361668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_4_tensor[0]"
      ],
      "metadata": {
        "id": "a1bdAkELdjRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fad72a1-1328-4b20-ef17-0334c2c4739a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
              "array([[[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)\n",
        "#size 120 # because 2*3*4*5"
      ],
      "metadata": {
        "id": "MU-uwjueeUgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91877667-80b2-4449-f2fb-85876fd569e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get various attributes of our tensor\n",
        "\n",
        "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Element along the 0 axis:\", rank_4_tensor.shape[0])\n",
        "print(\"Element along the last axis:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements in our tensor:\", tf.size(rank_4_tensor) )\n",
        "print(\"Total number of elements in our tensor:\", tf.size(rank_4_tensor).numpy() )"
      ],
      "metadata": {
        "id": "X9FBi4z4fsRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b33dec1-a027-410c-d255-2dc446621003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of every element: <dtype: 'float32'>\n",
            "Number of dimensions (rank): 4\n",
            "Shape of tensor: (2, 3, 4, 5)\n",
            "Element along the 0 axis: 2\n",
            "Element along the last axis: 5\n",
            "Total number of elements in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n",
            "Total number of elements in our tensor: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing and expanding tensors\n",
        "Tesor can be index just like python list"
      ],
      "metadata": {
        "id": "j_DzG1V3hYu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the first 2 elements of each dimension\n",
        "rank_4_tensor[:2,:2,:2,:2]"
      ],
      "metadata": {
        "id": "Q2dDDYjXhc1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22eab2e4-6b24-47ec-e4f2-fd6a595cd48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first element from each dimension from each index ecept for the final one\n",
        "\n",
        "rank_4_tensor[:1,:1,:1,:]"
      ],
      "metadata": {
        "id": "gPzIvIdMiLMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612f5a44-ea1d-4b87-8b74-71a252bb3a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a rank 2 tensor (2 dimensions)\n",
        "rank_2_tensor = tf.constant([[10,7],\n",
        "                            [3,4]])\n",
        "\n",
        "rank_2_tensor.shape, rank_2_tensor.ndim"
      ],
      "metadata": {
        "id": "tV-UPVGHjHJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5e85fc-36aa-420a-e10a-91287f31ef08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 2]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the las item of each row of our rank 2 tensor\n",
        "rank_2_tensor[:,-1]"
      ],
      "metadata": {
        "id": "ipzci2CajsTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ad4045-3708-4f5a-95d5-f78f5eaa78a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add in extra dimension\n",
        "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
        "rank_3_tensor"
      ],
      "metadata": {
        "id": "v6MpabBpl8Jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d35e7dd-b0aa-430e-af47-a4b30f177c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[10],\n",
              "        [ 7]],\n",
              "\n",
              "       [[ 3],\n",
              "        [ 4]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative to tf.newaxis\n",
        "tf.expand_dims(rank_2_tensor, axis=-1) #-1 is to put the new axis at the end"
      ],
      "metadata": {
        "id": "bV6IB0jamc5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb94ce3-63ea-4163-a55c-1cf59dbeede6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[10],\n",
              "        [ 7]],\n",
              "\n",
              "       [[ 3],\n",
              "        [ 4]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(rank_2_tensor, axis=0)"
      ],
      "metadata": {
        "id": "PzKO1b2_mtJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e923d0-d0bc-4ef0-8ec2-e205c9c98df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
              "array([[[10,  7],\n",
              "        [ 3,  4]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating tensors\n",
        "\n",
        "**Basic Operations**\n",
        "\n",
        "`+`,`-`,`*`"
      ],
      "metadata": {
        "id": "nNkNAko6m-gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add values to a tensor using the addtion operator\n",
        "\n",
        "tensor = tf.constant([[10,7],\n",
        "                      [3,4]])\n",
        "tensor + 10"
      ],
      "metadata": {
        "id": "-cOA62TnvFCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4068563f-cf1e-4ed1-df97-28d73d38108e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[20, 17],\n",
              "       [13, 14]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Original tensor is unchanged\n",
        "\n",
        "tensor"
      ],
      "metadata": {
        "id": "LGU1lkGgvoV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f747614e-2c0a-4366-a006-399829c9efec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiplication also works\n",
        "tensor *10"
      ],
      "metadata": {
        "id": "It086kRMv6mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77299ee7-12c9-4d8a-ee21-b3683ce04b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[100,  70],\n",
              "       [ 30,  40]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substraction works\n",
        "\n",
        "tensor - 10"
      ],
      "metadata": {
        "id": "hAbNJ-3mv-u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c7e427-a3d9-4242-d151-784dc5d5d261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 0, -3],\n",
              "       [-7, -6]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the tensorflow buitl-in function too\n",
        "tf.multiply(tensor,10)\n",
        "tf.add(tensor, 10)"
      ],
      "metadata": {
        "id": "6w8shdwOwCpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf4eb97-2dd0-40de-ff72-ea18f3182b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[20, 17],\n",
              "       [13, 14]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix multiplication**\n",
        "\n",
        "In machine learning, matrix multiplication is one of the most common tensor operations\n",
        "\n",
        "There 2 rules our tensors (or matrices) need to fulfill if we are going to matrix multiply them:\n",
        "\n",
        "1. The inner dimensions must match 3x**3** - **3**x2\n",
        "2. The resulting matrix has the shape of the outer dimensions **3**x2 - 3x**2**"
      ],
      "metadata": {
        "id": "kLZbLjT_LTyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import Image\n",
        "#Image(\"/content/drive/MyDrive/IMG_0938.png\")"
      ],
      "metadata": {
        "id": "g1r9zx8duTBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix multiplication in TF\n",
        "\n",
        "tf.matmul(tensor, tensor)"
      ],
      "metadata": {
        "id": "jG1GUC-Axzhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ac91cf-ffec-4ee3-a572-95c46a225311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[121,  98],\n",
              "       [ 42,  37]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix multiplication with Python operator \"@\"\n",
        "\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "id": "RQf_RRrn5ANK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a0bdd2-7e80-44c0-a6fd-10090b5f5ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[121,  98],\n",
              "       [ 42,  37]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Createa tensor (3,2) \n",
        "X = tf.constant([[1,2],\n",
        "                 [3,3],\n",
        "                 [5,6]])\n",
        "\n",
        "Y = tf.constant([[7,8],\n",
        "                 [9,10],\n",
        "                 [11,12]])\n",
        "\n",
        "X,Y"
      ],
      "metadata": {
        "id": "-A1QBo3OJcwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c3488f-5f3d-4341-90f7-de39780a9590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 3],\n",
              "        [5, 6]], dtype=int32)>, <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiply tensors of same shape\n",
        "tf.matmul(X,Y) # gives error"
      ],
      "metadata": {
        "id": "nQ-7_NUcJ6KV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "d9abbd6c-001e-49a1-db0f-b64cfb0a9f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-2ed9f12e97f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix multiply tensors of same shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gives error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets change the shape of Y\n",
        "tf.reshape(Y, shape=(2,3))"
      ],
      "metadata": {
        "id": "UJI20N-5KX35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbfc070-43b8-484b-8183-2eb935d17d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 7,  8,  9],\n",
              "       [10, 11, 12]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to multiply X by reshape Y\n",
        "X @ tf.reshape(Y,shape=(2,3))"
      ],
      "metadata": {
        "id": "PHL1LRwYrTS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8653a0b5-0ee3-4697-a45f-7746b095f99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 51,  57,  63],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.matmul(X,tf.reshape(Y,shape=(2,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcHDueZiMSEM",
        "outputId": "67d121e2-f08c-412e-dbb2-1eaec46acd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 51,  57,  63],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try change the shape of X instead of Y\n",
        "tf.matmul(tf.reshape(X,shape=(2,3)),Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW1y-vM0Mh2e",
        "outputId": "2c8e0560-7d96-4a36-bac7-2b1c668fad8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 58,  64],\n",
              "       [132, 146]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can do the same with transpose\n",
        "X,tf.transpose(X), tf.reshape(X,shape=(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RftEox-KNuys",
        "outputId": "91dbd40f-1f11-4cd0-8da8-783196c7ed7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 3],\n",
              "        [5, 6]], dtype=int32)>, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 3, 5],\n",
              "        [2, 3, 6]], dtype=int32)>, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 2, 3],\n",
              "        [3, 5, 6]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz multiplication with transpose rather than reshape\n",
        "\n",
        "tf.matmul(tf.transpose(X),Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq-yIgZYOfMk",
        "outputId": "9f6dc70f-5262-4046-d1d7-2baab56ed257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [107, 118]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dot product**\n",
        "\n",
        "Matrix multiplication is also refferred to as the dot product.\n",
        "\n",
        "You can perform matrix multiplication using:\n",
        "\n",
        "* `tf.matmul()`\n",
        "* `tf.tensordot()`"
      ],
      "metadata": {
        "id": "yuK1fA6oQdNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the dot product on X and Y (requires X or Y to be transposed)\n",
        "\n",
        "tf.tensordot(tf.transpose(X),Y,axes=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArT5x_5oQ4QG",
        "outputId": "507f9b8b-ce31-46df-d9b6-9ce7b94f846a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [107, 118]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform matrix multiplication between X and Y (transposed)\n",
        "tf.matmul(X, tf.transpose(Y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m4Pdt-WRnl7",
        "outputId": "465ca0a8-dd83-44d5-c182-f4837880352e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 23,  29,  35],\n",
              "       [ 45,  57,  69],\n",
              "       [ 83, 105, 127]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform matrix multiplication between X and Y (reshaped)\n",
        "tf.matmul(X, tf.reshape(Y,shape=(2,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tf8zm82R6l5",
        "outputId": "2fad1ebb-1485-4f4f-bd70-4b8baaf21b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 51,  57,  63],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the values of Y, reshape Y and transposed Y\n",
        "print(\"Normal Y:\")\n",
        "print(Y, \"\\n\")\n",
        "\n",
        "\n",
        "print(\"Y reshaped to (2,3):\")\n",
        "print(tf.reshape(Y, shape=(2,3)),\"\\n\")\n",
        "\n",
        "print(\"Y transposed:\")\n",
        "print(tf.transpose(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSLPHhn5SQNR",
        "outputId": "e5664da6-8dfc-4db9-e212-d0a5850579c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Y:\n",
            "tf.Tensor(\n",
            "[[ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]], shape=(3, 2), dtype=int32) \n",
            "\n",
            "Y reshaped to (2,3):\n",
            "tf.Tensor(\n",
            "[[ 7  8  9]\n",
            " [10 11 12]], shape=(2, 3), dtype=int32) \n",
            "\n",
            "Y transposed:\n",
            "tf.Tensor(\n",
            "[[ 7  9 11]\n",
            " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.matmul(X, tf.transpose(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKp2BtxCThZb",
        "outputId": "17394f93-a944-46b1-f647-fd2ba2610ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 23,  29,  35],\n",
              "       [ 45,  57,  69],\n",
              "       [ 83, 105, 127]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally when performing matrix multiplication on two tensors,\n",
        "and one of the axes does not line up,\n",
        "you will transpose (rather tahn reshape) on of\n",
        "the tensors to satisfy the matrix multiplication\n",
        "rules.\n"
      ],
      "metadata": {
        "id": "-iPuDqYLT18m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the data type of a tensor"
      ],
      "metadata": {
        "id": "3K2jwTRGBfnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with a default dadatype float32\n",
        "B = tf.constant([1.7,7.4])\n",
        "B.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vFX_rgbBo_p",
        "outputId": "49eeaa72-b74a-4b0c-ddcd-1a31f3a6cb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = tf.constant([7,10])\n",
        "C.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4LPBhKOCMOF",
        "outputId": "7770598b-a724-4e6f-e328-850216521ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.int32"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change tp float32 to float16\n",
        "B = tf.cast(B, dtype=tf.float16)\n",
        "B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUe8YAQkCX5b",
        "outputId": "f535aa80-2b78-46d5-bb83-d749fd87612f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change from int32 to fload32\n",
        "E = tf.cast(B, dtype=tf.float32)\n",
        "E"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZUddSy9DQ9n",
        "outputId": "b5759379-f7ac-4e03-9292-5a963260342e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7001953, 7.3984375], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_float16 = tf.cast(E, dtype=tf.float16)\n",
        "E_float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkEwvWZQFHpc",
        "outputId": "819c7a90-003d-4278-e1cb-9833a6b01252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregating tensors\n",
        "\n",
        "Aggregating tensors = condensing them to multiple values down to a smaller amount of values"
      ],
      "metadata": {
        "id": "DPwTttbdFYDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the absolute values\n",
        "\n",
        "D = tf.constant([[-7,-10]])\n",
        "tf.abs(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq-bwhXkFbQg",
        "outputId": "bec08718-7554-4b4f-c826-5090e442a54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[ 7, 10]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets go through the following forms of aggregation:\n",
        "* Get the minimun\n",
        "* Get the maximun\n",
        "* Get the mean of a tensor\n",
        "* Get the sum of a tensor"
      ],
      "metadata": {
        "id": "GrTFVXZYZF7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a random tensor width values between 0 and 100 of size 50\n",
        "E = tf.constant(np.random.randint(0,100,size=50))\n",
        "E\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LCSsXDOZYvb",
        "outputId": "8c2d648d-6613-46ec-b7aa-6e47621016b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([16, 20, 51, 95, 95,  5, 94, 77, 76, 82, 66, 14, 86, 26, 56, 14, 60,\n",
              "        0, 85, 32, 98, 79, 87, 77, 50, 74, 36, 24, 20, 78,  8, 63, 43, 29,\n",
              "       73, 17, 44, 37, 69, 42, 91, 36, 76, 22, 50, 97, 50, 55, 73, 19])>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.size(E), E.shape, E.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVWNcfxlao0d",
        "outputId": "f2adefb9-15d9-4271-f792-eb022f7d056f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int32, numpy=50>, TensorShape([50]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the minimun\n",
        "tf.reduce_min(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-oyprvVawP9",
        "outputId": "51b33428-e737-4642-92a5-03727fdc053f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximn\n",
        "tf.reduce_max(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro1yyUYTa5ID",
        "outputId": "436eaa8c-e7d9-4cc5-e55b-42a7005ec91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=98>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the mean\n",
        "tf.reduce_mean(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXIvgpP2a-qc",
        "outputId": "36a026a9-d440-4e9b-de62-9f3972253808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=53>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the sum\n",
        "tf.reduce_sum(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iQPSRFGbDi6",
        "outputId": "4d9b3f2a-5f64-4004-8ab3-71a55c24a48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=2667>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the variance\n",
        "import tensorflow_probability as tfp\n",
        "tfp.stats.variance(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3h5LYo0cLgW",
        "outputId": "073b094f-02a1-4bb2-ae08-0520ca6f9155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=819>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the standard deviation\n",
        "tf.math.reduce_std(tf.cast(E,dtype=tf.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06igpf9HeFEv",
        "outputId": "2a4684bb-0656-4cdb-8a94-acb5588204e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=28.6186>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the positional maximun and minimun\n",
        "\n"
      ],
      "metadata": {
        "id": "R_anGfBkfLyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new tensor for finding positional mimun and maximun\n",
        "tf.random.set_seed(42)\n",
        "F = tf.random.uniform(shape=[50])\n",
        "F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAJZ2RS-fUbH",
        "outputId": "1fa2c67e-df2b-41df-c140-c27768f671c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the positional max\n",
        "tf.argmax(F)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_wTsoDvhH6d",
        "outputId": "0371f2dd-b145-44bf-dada-5f35fc91e8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find on our largest value positional\n",
        "F[tf.argmax(F)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WviTnuKAhWT8",
        "outputId": "ae5d4ef6-0854-46da-cf26-559a160b017d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the max value of F\n",
        "tf.reduce_max(F)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5LUgosohiKt",
        "outputId": "53004445-7992-4bd2-918d-df615fe2fa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality\n",
        "F[tf.argmax(F)] == tf.reduce_max(F)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEHtqMjohokF",
        "outputId": "174d1c45-600f-450b-bbc2-5f715063b9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the positional minimun\n",
        "tf.argmin(F)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwEtkPqniFdE",
        "outputId": "ae1b8d58-c5c4-4af0-f516-1bc570064689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=16>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the miminun using the positional minimun index\n",
        "F[tf.argmin(F)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "786nP4zQiLEb",
        "outputId": "abf55584-c722-4dcf-eada-4275f9264bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.009463668>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Squeezing a tensor (removin all single dimensions)"
      ],
      "metadata": {
        "id": "u-_WZcF0ihIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "G = tf.constant(tf.random.uniform(shape=[50]), shape=(1,1,1,1,50))\n",
        "G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk94QsAqimDw",
        "outputId": "24bd63fc-567a-45c1-daf3-72811386755d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
              "array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "           0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "           0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "           0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "           0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "           0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "           0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "           0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "           0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "           0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtdmK2mjjDmI",
        "outputId": "ec01a9df-9df0-4300-e00b-a52a51f171cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1, 1, 1, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_squeezed = tf.squeeze(G)\n",
        "G_squeezed, G_squeezed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCKTzo3sjFq7",
        "outputId": "111be611-8975-4555-9699-4594e3f08c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              " array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "        0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "        0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "        0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "        0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "        0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "        0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "        0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "        0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "        0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
              "       dtype=float32)>, TensorShape([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot enconding Tensors"
      ],
      "metadata": {
        "id": "5bJs27GujY20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of indices\n",
        "some_list = [0,1,2,3] \n",
        "\n",
        "#One hot encode our list of indices\n",
        "tf.one_hot(some_list, depth=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAmiIsvSjbrA",
        "outputId": "e812602f-2531-4019-9a76-10c061c69172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specific custom values for one-hot  encoding\n",
        "tf.one_hot(some_list,depth=4,on_value=\"AA\",off_value=\"ZZ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTy1_FeLkgoS",
        "outputId": "fa504add-7d71-42f0-b294-ac9a4997e78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
              "array([[b'AA', b'ZZ', b'ZZ', b'ZZ'],\n",
              "       [b'ZZ', b'AA', b'ZZ', b'ZZ'],\n",
              "       [b'ZZ', b'ZZ', b'AA', b'ZZ'],\n",
              "       [b'ZZ', b'ZZ', b'ZZ', b'AA']], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Squaring, log, square root"
      ],
      "metadata": {
        "id": "0CPcWGAf1G2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new twnsor\n",
        "H = tf.range(1,10)\n",
        "H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m49HlGo21Sry",
        "outputId": "bcbf1ab3-9f0e-4ff1-da31-80ff0a6c0d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Square it\n",
        "tf.square(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaAH-dUj1X06",
        "outputId": "310dafd4-8b11-4d33-a052-1b47402e9ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the square root (will error, method requires non-int type)\n",
        "tf.sqrt(H)"
      ],
      "metadata": {
        "id": "fNKWi-8B1-xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the square root\n",
        "\n",
        "tf.sqrt(tf.cast(H, dtype=tf.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJgAnVc01daU",
        "outputId": "26cd49cf-eef4-4473-b0ec-71dca75d8920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([0.99999994, 1.4142134 , 1.7320508 , 1.9999999 , 2.236068  ,\n",
              "       2.4494896 , 2.6457512 , 2.8284268 , 3.        ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the log\n",
        "\n",
        "tf.math.log(tf.cast(H, dtype=tf.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWvvk9Xa2NF1",
        "outputId": "cabaf2ee-2795-4dbf-941d-45f3b7c60882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
              "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors & Numpy\n",
        "\n",
        "Tensors flow interacts beautifully with numpy arrays"
      ],
      "metadata": {
        "id": "hOtOq5TK2sxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor directly from a Numpy array\n",
        "\n",
        "J = tf.constant(np.array([3.,7.,10.]) )\n",
        "\n",
        "J"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJDWdTCb2wEp",
        "outputId": "a9c8db58-4e81-4009-d097-18d6fd96bc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert our tensor back to numpy array\n",
        "\n",
        "np.array(J), type(np.array(J))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUQNG3xn3IPC",
        "outputId": "f6774890-f714-481c-8e3f-5a6b05ec227a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensor J to a Numpy array\n",
        "\n",
        "J.numpy(), type(J.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ApcxHpZ3Wjd",
        "outputId": "28ca5a61-3832-4026-f655-d32e4609b19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "J = tf.constant([3.])\n",
        "J.numpy()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TxK7QXi3lAZ",
        "outputId": "643ed30b-34f9-40fb-af2d-ff39b823e705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default type of each are aslighty different\n",
        "numpy_J = tf.constant(np.array([3.,7.,10.]))\n",
        "tensor_J = tf.constant([3.,7.,10.])\n",
        "\n",
        "# Check the datatypes of each\n",
        "\n",
        "numpy_J.dtype, tensor_J.dtype "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewVNUF8d3ysy",
        "outputId": "744080cb-2e1e-436b-c9e2-43f907896eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.float64, tf.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding access to GPUs"
      ],
      "metadata": {
        "id": "1gKhf4gE4_-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_logical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x99zK1p55DDS",
        "outputId": "0ee019d8-b483-4db6-d038-6130f36fcf78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66y9CwoY5gtS",
        "outputId": "6e6f4959-ee61-4c5d-f9dc-68cace494903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If you have access to a CUDA-enabled GPU, Tensorflow will automatically use it whenever possible"
      ],
      "metadata": {
        "id": "2RRF-FWoQh_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Regression with TensorFlow"
      ],
      "metadata": {
        "id": "S1VmITSK4dC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to regression with neural netwroks in TF\n",
        "\n",
        "There are many definitions for a regression problema but in pur case, ew're going to simplify it: prediction a numerical variable based on some other combination of variables, even shorter... predicting a number."
      ],
      "metadata": {
        "id": "lMQeJdPWCI0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TF\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "r9D-KmDKCq5l"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating some data to view and fit"
      ],
      "metadata": {
        "id": "IbeeaKjnDBL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create features\n",
        "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "\n",
        "#Create labels\n",
        "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
        "\n",
        "#Visualize it\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "SFfVxAQLDIe2",
        "outputId": "c4ad88db-9bb8-4e22-e995-e9dc48ac5242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f2b169fd750>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPXp2na3EXR4",
        "outputId": "f495a23b-29ea-4443-80e5-00532ddd73b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "s7Nb5sANEg8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price predictiong problem\n",
        "house_info = tf.constant([\"Bedroom\",\"bathroom\",\"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info,house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nikMR-vlEjki",
        "outputId": "c2a76803-6e25-41d0-96cb-248e986034a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0],y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzZdmoO0GFlD",
        "outputId": "22b7ccf2-9877-4f19-f088-c59d8b183a17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1],y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Guldq3GKBF",
        "outputId": "bdaedd93-d93a-4f34-f8d3-69ba79f7677d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "\n",
        "input_shape, output_shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLW0a9tLFnBm",
        "outputId": "390477bc-2d47-43a5-feb1-7b462dcc3532"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn our Numpy arrays into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wA_zLoCHMf3",
        "outputId": "88b0ff64-771d-4620-e8eb-9fd484c8e133"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy4U5W6XHlpv",
        "outputId": "5521bd1a-71cc-477b-f162-443bd4a5028e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "GIFvEe6uH1Ur",
        "outputId": "8021e3ae-efd4-410a-c1c6-f2b60f75a47b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f2b169fd610>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "1. **Creating a model** - Define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - Define the loss function (in other words, the function which tells our model how wrong it is) and the optimizaer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - Letting the model try to find patterns between X & y (features and labels)."
      ],
      "metadata": {
        "id": "MPTcKxIWIVnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # MAE is short for Mean Absolute Error\n",
        "              optimizer=tf.keras.optimizers.SGD(), #SGD is short for Stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwSETrtgJPOJ",
        "outputId": "182fb3b3-f065-4a9e-b0aa-4f084594beab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b12744150>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BheJ_NuHPiK5",
        "outputId": "27170088-26e2-436f-dab8-d4c093c33f65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGoBnrXRPmvS",
        "outputId": "bac3b104-4a02-4b5e-f38c-98fea5a31aab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "1. **Creating a model** - Here we might add more layers, increase the number of hidden units (all called neuron) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting the model** - Here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "lGx1ABTNQen2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import logProcesses\n",
        "# Lets rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "               optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# 3. Fit the model (this time we will train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1),y, epochs=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQPh1RiWbhQD",
        "outputId": "c0126145-97be-4b4d-b88e-9afaab2997ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8756 - mae: 6.8756\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8700 - mae: 6.8700\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8644 - mae: 6.8644\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8588 - mae: 6.8588\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8531 - mae: 6.8531\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8475 - mae: 6.8475\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8419 - mae: 6.8419\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8363 - mae: 6.8363\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8306 - mae: 6.8306\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8250 - mae: 6.8250\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8194 - mae: 6.8194\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8138 - mae: 6.8138\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8081 - mae: 6.8081\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8025 - mae: 6.8025\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7969 - mae: 6.7969\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7913 - mae: 6.7913\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.7856 - mae: 6.7856\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7800 - mae: 6.7800\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7744 - mae: 6.7744\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7688 - mae: 6.7688\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7631 - mae: 6.7631\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.7575 - mae: 6.7575\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7519 - mae: 6.7519\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7463 - mae: 6.7463\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7406 - mae: 6.7406\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.7350 - mae: 6.7350\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7294 - mae: 6.7294\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7238 - mae: 6.7238\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7181 - mae: 6.7181\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7125 - mae: 6.7125\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7069 - mae: 6.7069\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7013 - mae: 6.7013\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.6956 - mae: 6.6956\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.6900 - mae: 6.6900\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6844 - mae: 6.6844\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6787 - mae: 6.6787\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6731 - mae: 6.6731\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6675 - mae: 6.6675\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6619 - mae: 6.6619\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6562 - mae: 6.6562\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6506 - mae: 6.6506\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6450 - mae: 6.6450\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6394 - mae: 6.6394\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6337 - mae: 6.6337\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6281 - mae: 6.6281\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6225 - mae: 6.6225\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6169 - mae: 6.6169\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6112 - mae: 6.6112\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6056 - mae: 6.6056\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6000 - mae: 6.6000\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5944 - mae: 6.5944\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5887 - mae: 6.5887\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5831 - mae: 6.5831\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5775 - mae: 6.5775\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5719 - mae: 6.5719\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5662 - mae: 6.5662\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5606 - mae: 6.5606\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5550 - mae: 6.5550\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5494 - mae: 6.5494\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5437 - mae: 6.5437\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5381 - mae: 6.5381\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5325 - mae: 6.5325\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5269 - mae: 6.5269\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.5212 - mae: 6.5212\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.5156 - mae: 6.5156\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5100 - mae: 6.5100\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5044 - mae: 6.5044\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.4987 - mae: 6.4987\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4931 - mae: 6.4931\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4875 - mae: 6.4875\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4819 - mae: 6.4819\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4762 - mae: 6.4762\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4706 - mae: 6.4706\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4650 - mae: 6.4650\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.4594 - mae: 6.4594\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4537 - mae: 6.4537\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.4481 - mae: 6.4481\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.4425 - mae: 6.4425\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4369 - mae: 6.4369\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4312 - mae: 6.4312\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.4256 - mae: 6.4256\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.4200 - mae: 6.4200\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.4144 - mae: 6.4144\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4087 - mae: 6.4087\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4031 - mae: 6.4031\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.3975 - mae: 6.3975\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.3919 - mae: 6.3919\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3862 - mae: 6.3862\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.3806 - mae: 6.3806\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3750 - mae: 6.3750\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3694 - mae: 6.3694\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.3637 - mae: 6.3637\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3581 - mae: 6.3581\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3525 - mae: 6.3525\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3469 - mae: 6.3469\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3412 - mae: 6.3412\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3356 - mae: 6.3356\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3300 - mae: 6.3300\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3244 - mae: 6.3244\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3187 - mae: 6.3187\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3131 - mae: 6.3131\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3075 - mae: 6.3075\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3019 - mae: 6.3019\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2962 - mae: 6.2962\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.2906 - mae: 6.2906\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2850 - mae: 6.2850\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2794 - mae: 6.2794\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.2737 - mae: 6.2737\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.2681 - mae: 6.2681\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2625 - mae: 6.2625\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.2569 - mae: 6.2569\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.2512 - mae: 6.2512\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.2456 - mae: 6.2456\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2400 - mae: 6.2400\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2344 - mae: 6.2344\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2287 - mae: 6.2287\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2231 - mae: 6.2231\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2175 - mae: 6.2175\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2119 - mae: 6.2119\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.2062 - mae: 6.2062\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.2006 - mae: 6.2006\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.1950 - mae: 6.1950\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.1894 - mae: 6.1894\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1837 - mae: 6.1837\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1781 - mae: 6.1781\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1725 - mae: 6.1725\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1669 - mae: 6.1669\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1612 - mae: 6.1612\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1556 - mae: 6.1556\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1500 - mae: 6.1500\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1444 - mae: 6.1444\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1387 - mae: 6.1387\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1331 - mae: 6.1331\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.1275 - mae: 6.1275\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1219 - mae: 6.1219\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.1162 - mae: 6.1162\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1106 - mae: 6.1106\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1050 - mae: 6.1050\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0994 - mae: 6.0994\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0937 - mae: 6.0937\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0881 - mae: 6.0881\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0825 - mae: 6.0825\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0769 - mae: 6.0769\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0712 - mae: 6.0712\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0656 - mae: 6.0656\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0600 - mae: 6.0600\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0544 - mae: 6.0544\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0487 - mae: 6.0487\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0431 - mae: 6.0431\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0375 - mae: 6.0375\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0319 - mae: 6.0319\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.0262 - mae: 6.0262\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0206 - mae: 6.0206\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.0150 - mae: 6.0150\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0094 - mae: 6.0094\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 6.0037 - mae: 6.0037\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 5.9981 - mae: 5.9981\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.9925 - mae: 5.9925\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9869 - mae: 5.9869\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9812 - mae: 5.9812\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.9756 - mae: 5.9756\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9700 - mae: 5.9700\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9644 - mae: 5.9644\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.9587 - mae: 5.9587\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9531 - mae: 5.9531\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.9475 - mae: 5.9475\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.9419 - mae: 5.9419\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9362 - mae: 5.9362\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9306 - mae: 5.9306\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9250 - mae: 5.9250\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9194 - mae: 5.9194\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9137 - mae: 5.9137\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9081 - mae: 5.9081\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9025 - mae: 5.9025\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8969 - mae: 5.8969\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8912 - mae: 5.8912\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8856 - mae: 5.8856\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8800 - mae: 5.8800\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8744 - mae: 5.8744\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8687 - mae: 5.8687\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8631 - mae: 5.8631\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.8575 - mae: 5.8575\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8519 - mae: 5.8519\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8462 - mae: 5.8462\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.8406 - mae: 5.8406\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8350 - mae: 5.8350\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8294 - mae: 5.8294\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.8237 - mae: 5.8237\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8181 - mae: 5.8181\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8125 - mae: 5.8125\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.8069 - mae: 5.8069\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8012 - mae: 5.8012\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7956 - mae: 5.7956\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7900 - mae: 5.7900\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.7844 - mae: 5.7844\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.7799 - mae: 5.7799\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.7750 - mae: 5.7750\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7694 - mae: 5.7694\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.7637 - mae: 5.7637\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7581 - mae: 5.7581\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7525 - mae: 5.7525\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7469 - mae: 5.7469\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7412 - mae: 5.7412\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7356 - mae: 5.7356\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7300 - mae: 5.7300\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7244 - mae: 5.7244\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.7187 - mae: 5.7187\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.7131 - mae: 5.7131\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7075 - mae: 5.7075\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 5.7019 - mae: 5.7019\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6962 - mae: 5.6962\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6906 - mae: 5.6906\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.6850 - mae: 5.6850\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.6794 - mae: 5.6794\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.6737 - mae: 5.6737\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.6681 - mae: 5.6681\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.6625 - mae: 5.6625\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.6569 - mae: 5.6569\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.6512 - mae: 5.6512\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.6456 - mae: 5.6456\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6400 - mae: 5.6400\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6344 - mae: 5.6344\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.6287 - mae: 5.6287\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.6231 - mae: 5.6231\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.6175 - mae: 5.6175\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6119 - mae: 5.6119\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6062 - mae: 5.6062\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.6006 - mae: 5.6006\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.5950 - mae: 5.5950\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5894 - mae: 5.5894\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5837 - mae: 5.5837\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5781 - mae: 5.5781\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.5725 - mae: 5.5725\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5669 - mae: 5.5669\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.5612 - mae: 5.5612\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.5556 - mae: 5.5556\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5518 - mae: 5.5518\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.5462 - mae: 5.5462\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5406 - mae: 5.5406\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.5350 - mae: 5.5350\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.5294 - mae: 5.5294\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5237 - mae: 5.5237\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5181 - mae: 5.5181\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5125 - mae: 5.5125\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5069 - mae: 5.5069\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5012 - mae: 5.5012\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4956 - mae: 5.4956\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.4900 - mae: 5.4900\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.4844 - mae: 5.4844\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4787 - mae: 5.4787\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4731 - mae: 5.4731\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4675 - mae: 5.4675\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4619 - mae: 5.4619\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4562 - mae: 5.4562\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4506 - mae: 5.4506\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4450 - mae: 5.4450\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4394 - mae: 5.4394\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4337 - mae: 5.4337\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4281 - mae: 5.4281\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4225 - mae: 5.4225\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4169 - mae: 5.4169\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4113 - mae: 5.4113\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4056 - mae: 5.4056\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4000 - mae: 5.4000\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3944 - mae: 5.3944\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3888 - mae: 5.3888\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3831 - mae: 5.3831\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3775 - mae: 5.3775\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3719 - mae: 5.3719\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3663 - mae: 5.3663\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3606 - mae: 5.3606\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3550 - mae: 5.3550\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3494 - mae: 5.3494\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3438 - mae: 5.3438\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3381 - mae: 5.3381\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.3325 - mae: 5.3325\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3274 - mae: 5.3274\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3231 - mae: 5.3231\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3175 - mae: 5.3175\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3119 - mae: 5.3119\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3063 - mae: 5.3063\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3006 - mae: 5.3006\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2950 - mae: 5.2950\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2894 - mae: 5.2894\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2838 - mae: 5.2838\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2781 - mae: 5.2781\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2725 - mae: 5.2725\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2669 - mae: 5.2669\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2613 - mae: 5.2613\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2556 - mae: 5.2556\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2500 - mae: 5.2500\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.2444 - mae: 5.2444\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2388 - mae: 5.2388\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2331 - mae: 5.2331\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2275 - mae: 5.2275\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2219 - mae: 5.2219\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.2163 - mae: 5.2163\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2106 - mae: 5.2106\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2050 - mae: 5.2050\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1994 - mae: 5.1994\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1938 - mae: 5.1938\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1881 - mae: 5.1881\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1825 - mae: 5.1825\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1769 - mae: 5.1769\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1713 - mae: 5.1713\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1656 - mae: 5.1656\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.1600 - mae: 5.1600\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1544 - mae: 5.1544\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1488 - mae: 5.1488\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1431 - mae: 5.1431\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.1375 - mae: 5.1375\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.1319 - mae: 5.1319\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1263 - mae: 5.1263\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.1206 - mae: 5.1206\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1150 - mae: 5.1150\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.1094 - mae: 5.1094\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.1038 - mae: 5.1038\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.0993 - mae: 5.0993\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.0944 - mae: 5.0944\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.0888 - mae: 5.0888\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0831 - mae: 5.0831\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0775 - mae: 5.0775\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0719 - mae: 5.0719\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0663 - mae: 5.0663\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0606 - mae: 5.0606\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0550 - mae: 5.0550\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0494 - mae: 5.0494\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0438 - mae: 5.0438\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0381 - mae: 5.0381\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0325 - mae: 5.0325\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0269 - mae: 5.0269\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0213 - mae: 5.0213\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0156 - mae: 5.0156\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0100 - mae: 5.0100\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0044 - mae: 5.0044\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.9988 - mae: 4.9988\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9931 - mae: 4.9931\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.9875 - mae: 4.9875\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.9819 - mae: 4.9819\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9763 - mae: 4.9763\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9706 - mae: 4.9706\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9650 - mae: 4.9650\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9594 - mae: 4.9594\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9538 - mae: 4.9538\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9481 - mae: 4.9481\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9425 - mae: 4.9425\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9369 - mae: 4.9369\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9313 - mae: 4.9313\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9256 - mae: 4.9256\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9200 - mae: 4.9200\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.9144 - mae: 4.9144\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.9088 - mae: 4.9088\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.9031 - mae: 4.9031\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.8975 - mae: 4.8975\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8919 - mae: 4.8919\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8863 - mae: 4.8863\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8806 - mae: 4.8806\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8750 - mae: 4.8750\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8712 - mae: 4.8712\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.8656 - mae: 4.8656\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.8600 - mae: 4.8600\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.8544 - mae: 4.8544\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4.8488 - mae: 4.8488\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.8431 - mae: 4.8431\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8375 - mae: 4.8375\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8319 - mae: 4.8319\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8263 - mae: 4.8263\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.8206 - mae: 4.8206\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8150 - mae: 4.8150\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8094 - mae: 4.8094\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8038 - mae: 4.8038\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7981 - mae: 4.7981\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7925 - mae: 4.7925\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.7869 - mae: 4.7869\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.7813 - mae: 4.7813\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.7756 - mae: 4.7756\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7700 - mae: 4.7700\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7644 - mae: 4.7644\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.7588 - mae: 4.7588\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.7531 - mae: 4.7531\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.7475 - mae: 4.7475\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7419 - mae: 4.7419\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7363 - mae: 4.7363\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.7306 - mae: 4.7306\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4.7250 - mae: 4.7250\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4.7194 - mae: 4.7194\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.7138 - mae: 4.7138\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4.7081 - mae: 4.7081\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.7025 - mae: 4.7025\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.6969 - mae: 4.6969\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.6913 - mae: 4.6913\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.6856 - mae: 4.6856\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6800 - mae: 4.6800\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6744 - mae: 4.6744\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6688 - mae: 4.6688\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.6631 - mae: 4.6631\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6575 - mae: 4.6575\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6519 - mae: 4.6519\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6468 - mae: 4.6468\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6425 - mae: 4.6425\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6369 - mae: 4.6369\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6313 - mae: 4.6313\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6256 - mae: 4.6256\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6200 - mae: 4.6200\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6144 - mae: 4.6144\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6088 - mae: 4.6088\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6031 - mae: 4.6031\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5975 - mae: 4.5975\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.5919 - mae: 4.5919\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5863 - mae: 4.5863\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.5806 - mae: 4.5806\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5750 - mae: 4.5750\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5694 - mae: 4.5694\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5638 - mae: 4.5638\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.5581 - mae: 4.5581\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.5525 - mae: 4.5525\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5469 - mae: 4.5469\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5413 - mae: 4.5413\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.5356 - mae: 4.5356\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.5300 - mae: 4.5300\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.5244 - mae: 4.5244\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.5188 - mae: 4.5188\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.5131 - mae: 4.5131\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.5075 - mae: 4.5075\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.5019 - mae: 4.5019\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.4963 - mae: 4.4963\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.4906 - mae: 4.4906\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4850 - mae: 4.4850\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.4794 - mae: 4.4794\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.4738 - mae: 4.4738\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4681 - mae: 4.4681\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.4625 - mae: 4.4625\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4569 - mae: 4.4569\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4.4513 - mae: 4.4513\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.4456 - mae: 4.4456\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4400 - mae: 4.4400\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4344 - mae: 4.4344\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4.4288 - mae: 4.4288\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4231 - mae: 4.4231\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.4187 - mae: 4.4187\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.4138 - mae: 4.4138\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4081 - mae: 4.4081\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4025 - mae: 4.4025\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.3969 - mae: 4.3969\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3913 - mae: 4.3913\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.3856 - mae: 4.3856\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.3800 - mae: 4.3800\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.3744 - mae: 4.3744\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3688 - mae: 4.3688\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3631 - mae: 4.3631\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.3575 - mae: 4.3575\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.3519 - mae: 4.3519\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3463 - mae: 4.3463\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.3406 - mae: 4.3406\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3350 - mae: 4.3350\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3294 - mae: 4.3294\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3238 - mae: 4.3238\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3181 - mae: 4.3181\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.3125 - mae: 4.3125\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3069 - mae: 4.3069\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3013 - mae: 4.3013\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2956 - mae: 4.2956\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2900 - mae: 4.2900\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2844 - mae: 4.2844\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2788 - mae: 4.2788\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2731 - mae: 4.2731\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2675 - mae: 4.2675\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2619 - mae: 4.2619\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.2563 - mae: 4.2563\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2506 - mae: 4.2506\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2450 - mae: 4.2450\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2394 - mae: 4.2394\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2338 - mae: 4.2338\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2281 - mae: 4.2281\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2225 - mae: 4.2225\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2169 - mae: 4.2169\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2113 - mae: 4.2113\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2056 - mae: 4.2056\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2000 - mae: 4.2000\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1944 - mae: 4.1944\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1905 - mae: 4.1905\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1850 - mae: 4.1850\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1794 - mae: 4.1794\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1738 - mae: 4.1738\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.1681 - mae: 4.1681\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1625 - mae: 4.1625\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.1569 - mae: 4.1569\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1512 - mae: 4.1512\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1456 - mae: 4.1456\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1400 - mae: 4.1400\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1344 - mae: 4.1344\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1287 - mae: 4.1287\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1231 - mae: 4.1231\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1175 - mae: 4.1175\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1119 - mae: 4.1119\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.1062 - mae: 4.1062\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.1006 - mae: 4.1006\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0950 - mae: 4.0950\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0894 - mae: 4.0894\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.0837 - mae: 4.0837\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.0781 - mae: 4.0781\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.0725 - mae: 4.0725\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0669 - mae: 4.0669\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.0612 - mae: 4.0612\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0556 - mae: 4.0556\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0500 - mae: 4.0500\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0444 - mae: 4.0444\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0387 - mae: 4.0387\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.0331 - mae: 4.0331\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0275 - mae: 4.0275\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0219 - mae: 4.0219\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0162 - mae: 4.0162\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0106 - mae: 4.0106\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0050 - mae: 4.0050\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9994 - mae: 3.9994\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.9937 - mae: 3.9937\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9881 - mae: 3.9881\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9825 - mae: 3.9825\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9769 - mae: 3.9769\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9712 - mae: 3.9712\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9661 - mae: 3.9661\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9619 - mae: 3.9619\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9562 - mae: 3.9562\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9506 - mae: 3.9506\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.9450 - mae: 3.9450\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.9394 - mae: 3.9394\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9337 - mae: 3.9337\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.9281 - mae: 3.9281\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.9225 - mae: 3.9225\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.9169 - mae: 3.9169\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.9112 - mae: 3.9112\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.9056 - mae: 3.9056\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9000 - mae: 3.9000\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8944 - mae: 3.8944\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8887 - mae: 3.8887\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8831 - mae: 3.8831\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8775 - mae: 3.8775\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8719 - mae: 3.8719\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8662 - mae: 3.8662\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8606 - mae: 3.8606\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8550 - mae: 3.8550\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8494 - mae: 3.8494\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8437 - mae: 3.8437\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8381 - mae: 3.8381\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8325 - mae: 3.8325\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8269 - mae: 3.8269\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8212 - mae: 3.8212\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8156 - mae: 3.8156\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8100 - mae: 3.8100\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8044 - mae: 3.8044\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7987 - mae: 3.7987\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7931 - mae: 3.7931\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7875 - mae: 3.7875\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7819 - mae: 3.7819\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7762 - mae: 3.7762\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7706 - mae: 3.7706\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7650 - mae: 3.7650\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7594 - mae: 3.7594\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7537 - mae: 3.7537\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7481 - mae: 3.7481\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7425 - mae: 3.7425\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7380 - mae: 3.7380\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7331 - mae: 3.7331\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7275 - mae: 3.7275\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7219 - mae: 3.7219\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7162 - mae: 3.7162\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7106 - mae: 3.7106\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7050 - mae: 3.7050\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6994 - mae: 3.6994\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6937 - mae: 3.6937\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6881 - mae: 3.6881\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6825 - mae: 3.6825\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6769 - mae: 3.6769\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6712 - mae: 3.6712\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6656 - mae: 3.6656\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6600 - mae: 3.6600\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6544 - mae: 3.6544\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6487 - mae: 3.6487\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6431 - mae: 3.6431\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6375 - mae: 3.6375\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6319 - mae: 3.6319\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3.6262 - mae: 3.6262\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.6206 - mae: 3.6206\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6150 - mae: 3.6150\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6094 - mae: 3.6094\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6037 - mae: 3.6037\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5981 - mae: 3.5981\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5925 - mae: 3.5925\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.5869 - mae: 3.5869\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5812 - mae: 3.5812\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5756 - mae: 3.5756\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5700 - mae: 3.5700\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5644 - mae: 3.5644\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5587 - mae: 3.5587\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5531 - mae: 3.5531\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5475 - mae: 3.5475\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5419 - mae: 3.5419\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5362 - mae: 3.5362\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5306 - mae: 3.5306\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5250 - mae: 3.5250\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5194 - mae: 3.5194\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5137 - mae: 3.5137\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5099 - mae: 3.5099\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5044 - mae: 3.5044\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4987 - mae: 3.4987\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4931 - mae: 3.4931\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4875 - mae: 3.4875\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4819 - mae: 3.4819\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4762 - mae: 3.4762\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4706 - mae: 3.4706\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4650 - mae: 3.4650\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.4594 - mae: 3.4594\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4537 - mae: 3.4537\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4481 - mae: 3.4481\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4425 - mae: 3.4425\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4369 - mae: 3.4369\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4312 - mae: 3.4312\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4256 - mae: 3.4256\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4200 - mae: 3.4200\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4144 - mae: 3.4144\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4087 - mae: 3.4087\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4031 - mae: 3.4031\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3975 - mae: 3.3975\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3919 - mae: 3.3919\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3862 - mae: 3.3862\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3806 - mae: 3.3806\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3750 - mae: 3.3750\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3694 - mae: 3.3694\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3637 - mae: 3.3637\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3581 - mae: 3.3581\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3525 - mae: 3.3525\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3469 - mae: 3.3469\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3412 - mae: 3.3412\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3356 - mae: 3.3356\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3300 - mae: 3.3300\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.3244 - mae: 3.3244\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3187 - mae: 3.3187\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3131 - mae: 3.3131\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3075 - mae: 3.3075\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.3019 - mae: 3.3019\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.2962 - mae: 3.2962\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2906 - mae: 3.2906\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2855 - mae: 3.2855\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2812 - mae: 3.2812\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2756 - mae: 3.2756\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2700 - mae: 3.2700\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2644 - mae: 3.2644\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2587 - mae: 3.2587\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2531 - mae: 3.2531\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2475 - mae: 3.2475\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2419 - mae: 3.2419\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2362 - mae: 3.2362\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2306 - mae: 3.2306\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2250 - mae: 3.2250\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2194 - mae: 3.2194\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2137 - mae: 3.2137\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.2081 - mae: 3.2081\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2025 - mae: 3.2025\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1969 - mae: 3.1969\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1912 - mae: 3.1912\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1856 - mae: 3.1856\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1800 - mae: 3.1800\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1744 - mae: 3.1744\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1687 - mae: 3.1687\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1631 - mae: 3.1631\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1575 - mae: 3.1575\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1519 - mae: 3.1519\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1462 - mae: 3.1462\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1406 - mae: 3.1406\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1350 - mae: 3.1350\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1294 - mae: 3.1294\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1237 - mae: 3.1237\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1181 - mae: 3.1181\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1125 - mae: 3.1125\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1069 - mae: 3.1069\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1012 - mae: 3.1012\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0956 - mae: 3.0956\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0900 - mae: 3.0900\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0844 - mae: 3.0844\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0787 - mae: 3.0787\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0731 - mae: 3.0731\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0675 - mae: 3.0675\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0619 - mae: 3.0619\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0574 - mae: 3.0574\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0525 - mae: 3.0525\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0468 - mae: 3.0468\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0412 - mae: 3.0412\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0356 - mae: 3.0356\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0300 - mae: 3.0300\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0243 - mae: 3.0243\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.0187 - mae: 3.0187\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0131 - mae: 3.0131\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0075 - mae: 3.0075\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0018 - mae: 3.0018\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9962 - mae: 2.9962\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9906 - mae: 2.9906\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9850 - mae: 2.9850\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9793 - mae: 2.9793\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9737 - mae: 2.9737\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9681 - mae: 2.9681\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9625 - mae: 2.9625\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9568 - mae: 2.9568\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9512 - mae: 2.9512\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9456 - mae: 2.9456\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9400 - mae: 2.9400\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9343 - mae: 2.9343\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9287 - mae: 2.9287\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9231 - mae: 2.9231\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9175 - mae: 2.9175\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9118 - mae: 2.9118\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9062 - mae: 2.9062\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9006 - mae: 2.9006\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8950 - mae: 2.8950\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8893 - mae: 2.8893\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8837 - mae: 2.8837\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8781 - mae: 2.8781\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8725 - mae: 2.8725\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8668 - mae: 2.8668\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8612 - mae: 2.8612\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8556 - mae: 2.8556\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8500 - mae: 2.8500\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8443 - mae: 2.8443\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8387 - mae: 2.8387\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8331 - mae: 2.8331\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8293 - mae: 2.8293\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8237 - mae: 2.8237\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8181 - mae: 2.8181\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8125 - mae: 2.8125\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8068 - mae: 2.8068\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8012 - mae: 2.8012\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7956 - mae: 2.7956\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7900 - mae: 2.7900\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7843 - mae: 2.7843\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7787 - mae: 2.7787\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7731 - mae: 2.7731\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7675 - mae: 2.7675\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7618 - mae: 2.7618\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7562 - mae: 2.7562\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7506 - mae: 2.7506\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7450 - mae: 2.7450\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7393 - mae: 2.7393\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7337 - mae: 2.7337\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7281 - mae: 2.7281\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7225 - mae: 2.7225\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7168 - mae: 2.7168\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7112 - mae: 2.7112\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7056 - mae: 2.7056\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7000 - mae: 2.7000\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6943 - mae: 2.6943\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6887 - mae: 2.6887\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6831 - mae: 2.6831\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6775 - mae: 2.6775\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6718 - mae: 2.6718\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6662 - mae: 2.6662\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6606 - mae: 2.6606\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6550 - mae: 2.6550\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6493 - mae: 2.6493\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6437 - mae: 2.6437\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6381 - mae: 2.6381\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6325 - mae: 2.6325\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6268 - mae: 2.6268\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6212 - mae: 2.6212\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6156 - mae: 2.6156\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6100 - mae: 2.6100\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6049 - mae: 2.6049\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6006 - mae: 2.6006\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5950 - mae: 2.5950\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5893 - mae: 2.5893\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5837 - mae: 2.5837\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5781 - mae: 2.5781\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5725 - mae: 2.5725\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.5668 - mae: 2.5668\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5612 - mae: 2.5612\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5556 - mae: 2.5556\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5500 - mae: 2.5500\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5443 - mae: 2.5443\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5387 - mae: 2.5387\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5331 - mae: 2.5331\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5275 - mae: 2.5275\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5218 - mae: 2.5218\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5162 - mae: 2.5162\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5106 - mae: 2.5106\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5050 - mae: 2.5050\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4993 - mae: 2.4993\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4937 - mae: 2.4937\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4881 - mae: 2.4881\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4825 - mae: 2.4825\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4768 - mae: 2.4768\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4712 - mae: 2.4712\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4656 - mae: 2.4656\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4600 - mae: 2.4600\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4543 - mae: 2.4543\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4487 - mae: 2.4487\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4431 - mae: 2.4431\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4375 - mae: 2.4375\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4318 - mae: 2.4318\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4262 - mae: 2.4262\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4206 - mae: 2.4206\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4150 - mae: 2.4150\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4093 - mae: 2.4093\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4037 - mae: 2.4037\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3981 - mae: 2.3981\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3925 - mae: 2.3925\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3868 - mae: 2.3868\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3812 - mae: 2.3812\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3767 - mae: 2.3767\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3718 - mae: 2.3718\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3662 - mae: 2.3662\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3606 - mae: 2.3606\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3550 - mae: 2.3550\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3493 - mae: 2.3493\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3437 - mae: 2.3437\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3381 - mae: 2.3381\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3325 - mae: 2.3325\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3268 - mae: 2.3268\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3212 - mae: 2.3212\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3156 - mae: 2.3156\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3100 - mae: 2.3100\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3043 - mae: 2.3043\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2987 - mae: 2.2987\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2931 - mae: 2.2931\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2875 - mae: 2.2875\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2818 - mae: 2.2818\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2762 - mae: 2.2762\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2706 - mae: 2.2706\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2650 - mae: 2.2650\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2593 - mae: 2.2593\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2537 - mae: 2.2537\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2481 - mae: 2.2481\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2425 - mae: 2.2425\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2368 - mae: 2.2368\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2312 - mae: 2.2312\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2256 - mae: 2.2256\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2200 - mae: 2.2200\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2143 - mae: 2.2143\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2087 - mae: 2.2087\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2031 - mae: 2.2031\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1975 - mae: 2.1975\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1918 - mae: 2.1918\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1862 - mae: 2.1862\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.1806 - mae: 2.1806\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1750 - mae: 2.1750\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1693 - mae: 2.1693\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1637 - mae: 2.1637\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1581 - mae: 2.1581\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1525 - mae: 2.1525\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1486 - mae: 2.1486\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1431 - mae: 2.1431\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1375 - mae: 2.1375\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1318 - mae: 2.1318\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1262 - mae: 2.1262\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1206 - mae: 2.1206\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1150 - mae: 2.1150\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1093 - mae: 2.1093\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1037 - mae: 2.1037\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0981 - mae: 2.0981\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0925 - mae: 2.0925\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0868 - mae: 2.0868\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0812 - mae: 2.0812\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0756 - mae: 2.0756\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0700 - mae: 2.0700\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0643 - mae: 2.0643\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0587 - mae: 2.0587\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0531 - mae: 2.0531\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0475 - mae: 2.0475\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0418 - mae: 2.0418\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0362 - mae: 2.0362\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0306 - mae: 2.0306\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0250 - mae: 2.0250\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0193 - mae: 2.0193\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0137 - mae: 2.0137\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0081 - mae: 2.0081\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0025 - mae: 2.0025\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9968 - mae: 1.9968\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9912 - mae: 1.9912\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9856 - mae: 1.9856\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9800 - mae: 1.9800\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9743 - mae: 1.9743\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9687 - mae: 1.9687\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9631 - mae: 1.9631\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9574 - mae: 1.9574\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9518 - mae: 1.9518\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9462 - mae: 1.9462\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9406 - mae: 1.9406\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9349 - mae: 1.9349\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9293 - mae: 1.9293\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9242 - mae: 1.9242\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9199 - mae: 1.9199\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9143 - mae: 1.9143\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9087 - mae: 1.9087\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9031 - mae: 1.9031\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8974 - mae: 1.8974\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8918 - mae: 1.8918\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8862 - mae: 1.8862\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8806 - mae: 1.8806\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8749 - mae: 1.8749\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8693 - mae: 1.8693\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8637 - mae: 1.8637\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8581 - mae: 1.8581\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8524 - mae: 1.8524\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8468 - mae: 1.8468\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8412 - mae: 1.8412\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8356 - mae: 1.8356\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8299 - mae: 1.8299\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8243 - mae: 1.8243\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8187 - mae: 1.8187\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8131 - mae: 1.8131\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8074 - mae: 1.8074\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8018 - mae: 1.8018\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7962 - mae: 1.7962\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7906 - mae: 1.7906\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7849 - mae: 1.7849\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7793 - mae: 1.7793\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7737 - mae: 1.7737\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7681 - mae: 1.7681\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7624 - mae: 1.7624\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7568 - mae: 1.7568\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7512 - mae: 1.7512\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7456 - mae: 1.7456\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7399 - mae: 1.7399\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7343 - mae: 1.7343\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7287 - mae: 1.7287\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7231 - mae: 1.7231\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7174 - mae: 1.7174\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7118 - mae: 1.7118\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7062 - mae: 1.7062\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7006 - mae: 1.7006\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6961 - mae: 1.6961\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6912 - mae: 1.6912\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6856 - mae: 1.6856\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6799 - mae: 1.6799\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6743 - mae: 1.6743\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6687 - mae: 1.6687\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6631 - mae: 1.6631\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6574 - mae: 1.6574\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6518 - mae: 1.6518\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.6462 - mae: 1.6462\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6406 - mae: 1.6406\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6349 - mae: 1.6349\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6293 - mae: 1.6293\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6237 - mae: 1.6237\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6181 - mae: 1.6181\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6124 - mae: 1.6124\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6068 - mae: 1.6068\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6012 - mae: 1.6012\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5956 - mae: 1.5956\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5899 - mae: 1.5899\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5843 - mae: 1.5843\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5787 - mae: 1.5787\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5731 - mae: 1.5731\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5674 - mae: 1.5674\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5618 - mae: 1.5618\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5562 - mae: 1.5562\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5506 - mae: 1.5506\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5449 - mae: 1.5449\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5393 - mae: 1.5393\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5337 - mae: 1.5337\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5281 - mae: 1.5281\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5224 - mae: 1.5224\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5168 - mae: 1.5168\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5112 - mae: 1.5112\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5056 - mae: 1.5056\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4999 - mae: 1.4999\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4943 - mae: 1.4943\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4887 - mae: 1.4887\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4831 - mae: 1.4831\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4774 - mae: 1.4774\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4718 - mae: 1.4718\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4680 - mae: 1.4680\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4624 - mae: 1.4624\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4568 - mae: 1.4568\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4512 - mae: 1.4512\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4456 - mae: 1.4456\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4399 - mae: 1.4399\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4343 - mae: 1.4343\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4287 - mae: 1.4287\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4231 - mae: 1.4231\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4174 - mae: 1.4174\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4118 - mae: 1.4118\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4062 - mae: 1.4062\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4006 - mae: 1.4006\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3949 - mae: 1.3949\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3893 - mae: 1.3893\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3837 - mae: 1.3837\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3781 - mae: 1.3781\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3724 - mae: 1.3724\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3668 - mae: 1.3668\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3612 - mae: 1.3612\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3556 - mae: 1.3556\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3499 - mae: 1.3499\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3443 - mae: 1.3443\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3387 - mae: 1.3387\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3331 - mae: 1.3331\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3274 - mae: 1.3274\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3218 - mae: 1.3218\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3162 - mae: 1.3162\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3106 - mae: 1.3106\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3049 - mae: 1.3049\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2993 - mae: 1.2993\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2937 - mae: 1.2937\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2881 - mae: 1.2881\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2824 - mae: 1.2824\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2768 - mae: 1.2768\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2712 - mae: 1.2712\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2656 - mae: 1.2656\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2599 - mae: 1.2599\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2543 - mae: 1.2543\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2487 - mae: 1.2487\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.2436 - mae: 1.2436\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2393 - mae: 1.2393\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2337 - mae: 1.2337\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2281 - mae: 1.2281\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2225 - mae: 1.2225\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2168 - mae: 1.2168\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2112 - mae: 1.2112\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2056 - mae: 1.2056\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2000 - mae: 1.2000\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1943 - mae: 1.1943\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1887 - mae: 1.1887\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1831 - mae: 1.1831\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1775 - mae: 1.1775\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1718 - mae: 1.1718\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1662 - mae: 1.1662\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.1606 - mae: 1.1606\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.1550 - mae: 1.1550\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1493 - mae: 1.1493\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1437 - mae: 1.1437\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1381 - mae: 1.1381\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1325 - mae: 1.1325\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1268 - mae: 1.1268\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1212 - mae: 1.1212\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1156 - mae: 1.1156\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1100 - mae: 1.1100\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1043 - mae: 1.1043\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0987 - mae: 1.0987\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0931 - mae: 1.0931\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0875 - mae: 1.0875\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0818 - mae: 1.0818\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0762 - mae: 1.0762\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0706 - mae: 1.0706\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0650 - mae: 1.0650\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0593 - mae: 1.0593\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0537 - mae: 1.0537\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0481 - mae: 1.0481\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0425 - mae: 1.0425\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0368 - mae: 1.0368\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0312 - mae: 1.0312\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0256 - mae: 1.0256\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0200 - mae: 1.0200\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0155 - mae: 1.0155\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0119 - mae: 1.0119\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0286 - mae: 1.0286\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9993 - mae: 0.9993\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9937 - mae: 0.9937\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9881 - mae: 0.9881\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9825 - mae: 0.9825\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9768 - mae: 0.9768\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9712 - mae: 0.9712\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9656 - mae: 0.9656\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9600 - mae: 0.9600\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9543 - mae: 0.9543\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9487 - mae: 0.9487\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9431 - mae: 0.9431\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9375 - mae: 0.9375\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9318 - mae: 0.9318\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9262 - mae: 0.9262\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9206 - mae: 0.9206\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9150 - mae: 0.9150\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9093 - mae: 0.9093\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9037 - mae: 0.9037\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8981 - mae: 0.8981\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8925 - mae: 0.8925\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8868 - mae: 0.8868\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8812 - mae: 0.8812\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8756 - mae: 0.8756\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8700 - mae: 0.8700\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8643 - mae: 0.8643\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8587 - mae: 0.8587\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8531 - mae: 0.8531\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8493 - mae: 0.8493\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8594 - mae: 0.8594\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8624 - mae: 0.8624\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8325 - mae: 0.8325\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8268 - mae: 0.8268\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8212 - mae: 0.8212\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8156 - mae: 0.8156\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8100 - mae: 0.8100\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8043 - mae: 0.8043\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7987 - mae: 0.7987\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7931 - mae: 0.7931\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7875 - mae: 0.7875\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7818 - mae: 0.7818\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7762 - mae: 0.7762\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7706 - mae: 0.7706\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7650 - mae: 0.7650\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7593 - mae: 0.7593\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7537 - mae: 0.7537\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7481 - mae: 0.7481\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7425 - mae: 0.7425\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7368 - mae: 0.7368\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7312 - mae: 0.7312\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7256 - mae: 0.7256\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7200 - mae: 0.7200\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7143 - mae: 0.7143\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7087 - mae: 0.7087\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7031 - mae: 0.7031\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6975 - mae: 0.6975\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6918 - mae: 0.6918\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6868 - mae: 0.6868\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7144 - mae: 0.7144\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6999 - mae: 0.6999\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6732 - mae: 0.6732\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7130 - mae: 0.7130\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6600 - mae: 0.6600\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6543 - mae: 0.6543\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6487 - mae: 0.6487\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6431 - mae: 0.6431\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6375 - mae: 0.6375\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6318 - mae: 0.6318\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6262 - mae: 0.6262\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6206 - mae: 0.6206\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6150 - mae: 0.6150\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6093 - mae: 0.6093\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6037 - mae: 0.6037\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5981 - mae: 0.5981\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5925 - mae: 0.5925\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5868 - mae: 0.5868\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5824 - mae: 0.5824\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6182 - mae: 0.6182\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5955 - mae: 0.5955\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5769 - mae: 0.5769\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6086 - mae: 0.6086\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5550 - mae: 0.5550\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5493 - mae: 0.5493\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5437 - mae: 0.5437\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5381 - mae: 0.5381\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5325 - mae: 0.5325\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5268 - mae: 0.5268\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5212 - mae: 0.5212\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5156 - mae: 0.5156\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5100 - mae: 0.5100\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5043 - mae: 0.5043\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4987 - mae: 0.4987\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4931 - mae: 0.4931\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4875 - mae: 0.4875\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4819 - mae: 0.4819\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - mae: 0.4780\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5219 - mae: 0.5219\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4911 - mae: 0.4911\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4807 - mae: 0.4807\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5043 - mae: 0.5043\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4500 - mae: 0.4500\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4443 - mae: 0.4443\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4387 - mae: 0.4387\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4331 - mae: 0.4331\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4275 - mae: 0.4275\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4219 - mae: 0.4219\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4162 - mae: 0.4162\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4106 - mae: 0.4106\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4050 - mae: 0.4050\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3994 - mae: 0.3994\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3937 - mae: 0.3937\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3881 - mae: 0.3881\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3825 - mae: 0.3825\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3774 - mae: 0.3774\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4332 - mae: 0.4332\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3905 - mae: 0.3905\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3919 - mae: 0.3919\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4073 - mae: 0.4073\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4232 - mae: 0.4232\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3630 - mae: 0.3630\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3819 - mae: 0.3819\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3766 - mae: 0.3766\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4132 - mae: 0.4132\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3355 - mae: 0.3355\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3719 - mae: 0.3719\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3486 - mae: 0.3486\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3307 - mae: 0.3307\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3779 - mae: 0.3779\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3619 - mae: 0.3619\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3211 - mae: 0.3211\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3207 - mae: 0.3207\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3473 - mae: 0.3473\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3519 - mae: 0.3519\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2936 - mae: 0.2936\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3107 - mae: 0.3107\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3166 - mae: 0.3166\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3419 - mae: 0.3419\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2661 - mae: 0.2661\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3007 - mae: 0.3007\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2860 - mae: 0.2860\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3319 - mae: 0.3319\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2386 - mae: 0.2386\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2907 - mae: 0.2907\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2554 - mae: 0.2554\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3219 - mae: 0.3219\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2111 - mae: 0.2111\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2807 - mae: 0.2807\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2248 - mae: 0.2248\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3119 - mae: 0.3119\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1894 - mae: 0.1894\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1837 - mae: 0.1837\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1781 - mae: 0.1781\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1725 - mae: 0.1725\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1686 - mae: 0.1686\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2407 - mae: 0.2407\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1866 - mae: 0.1866\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2719 - mae: 0.2719\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1462 - mae: 0.1462\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1406 - mae: 0.1406\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1350 - mae: 0.1350\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1299 - mae: 0.1299\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2082 - mae: 0.2082\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1504 - mae: 0.1504\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2429 - mae: 0.2429\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1716 - mae: 0.1716\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2119 - mae: 0.2119\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1111 - mae: 0.1111\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1707 - mae: 0.1707\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1410 - mae: 0.1410\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2148 - mae: 0.2148\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1702 - mae: 0.1702\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2527 - mae: 0.2527\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1852 - mae: 0.1852\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2345 - mae: 0.2345\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2002 - mae: 0.2002\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2164 - mae: 0.2164\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2152 - mae: 0.2152\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1983 - mae: 0.1983\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2302 - mae: 0.2302\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1810 - mae: 0.1810\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1852 - mae: 0.1852\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2233 - mae: 0.2233\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2002 - mae: 0.2002\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2052 - mae: 0.2052\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2152 - mae: 0.2152\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1870 - mae: 0.1870\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2325 - mae: 0.2325\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2014 - mae: 0.2014\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2169 - mae: 0.2169\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2158 - mae: 0.2158\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2013 - mae: 0.2013\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2302 - mae: 0.2302\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1857 - mae: 0.1857\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2445 - mae: 0.2445\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1702 - mae: 0.1702\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2264 - mae: 0.2264\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1875 - mae: 0.1875\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2408 - mae: 0.2408\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1719 - mae: 0.1719\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2552 - mae: 0.2552\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1563 - mae: 0.1563\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.2695 - mae: 0.2695\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.1407 - mae: 0.1407\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2839 - mae: 0.2839\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1252 - mae: 0.1252\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2658 - mae: 0.2658\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.2806\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mae: 0.1425\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2806 - mae: 0.2806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b125e1810>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDZAXkYWsRrL",
        "outputId": "c06dd6f7-f4c3-4fcb-a1c4-a9e2dcd600dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets predict\n",
        "\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhv2IFJSsVKD",
        "outputId": "a2e2b8be-51b2-4a99-ae90-841f1a5ffb42"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.359833]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another chnges to improve the model\n",
        "\n",
        "# 1 create the model with an extra hidden layer\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), #agregar el learning rate mejoro la prediccion\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1),y, epochs=200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI0uBDXjtq8X",
        "outputId": "d0e32836-10c3-466b-c513-93ba367b76e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 2s 2s/step - loss: 12.9513 - mae: 12.9513\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.5285 - mae: 12.5285\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.1098 - mae: 12.1098\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.6979 - mae: 11.6979\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.2893 - mae: 11.2893\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.8902 - mae: 10.8902\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.5068 - mae: 10.5068\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1209 - mae: 10.1209\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.7311 - mae: 9.7311\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3167 - mae: 9.3167\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8797 - mae: 8.8797\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4478 - mae: 8.4478\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0554 - mae: 8.0554\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6417 - mae: 7.6417\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2037 - mae: 7.2037\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7338 - mae: 6.7338\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2391 - mae: 6.2391\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7124 - mae: 5.7124\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1505 - mae: 5.1505\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.5515 - mae: 4.5515\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.1226 - mae: 4.1226\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9248 - mae: 3.9248\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0670 - mae: 4.0670\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.1968 - mae: 4.1968\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.3344 - mae: 4.3344\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5500 - mae: 4.5500\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6800 - mae: 4.6800\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7330 - mae: 4.7330\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.7179 - mae: 4.7179\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.6452 - mae: 4.6452\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.5235 - mae: 4.5235\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.3622 - mae: 4.3622\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2044 - mae: 4.2044\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1277 - mae: 4.1277\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0525 - mae: 4.0525\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.9784 - mae: 3.9784\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.9052 - mae: 3.9052\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8333 - mae: 3.8333\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.8401 - mae: 3.8401\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8941 - mae: 3.8941\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9317 - mae: 3.9317\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9546 - mae: 3.9546\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9649 - mae: 3.9649\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9633 - mae: 3.9633\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9511 - mae: 3.9511\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9296 - mae: 3.9296\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8990 - mae: 3.8990\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8589 - mae: 3.8589\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8110 - mae: 3.8110\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7558 - mae: 3.7558\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6930 - mae: 3.6930\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7065 - mae: 3.7065\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7302 - mae: 3.7302\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7500 - mae: 3.7500\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7534 - mae: 3.7534\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7540 - mae: 3.7540\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7465 - mae: 3.7465\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7322 - mae: 3.7322\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7112 - mae: 3.7112\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6847 - mae: 3.6847\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6529 - mae: 3.6529\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6281 - mae: 3.6281\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5796 - mae: 3.5796\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6103 - mae: 3.6103\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6314 - mae: 3.6314\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6358 - mae: 3.6358\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6249 - mae: 3.6249\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5999 - mae: 3.5999\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5609 - mae: 3.5609\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5099 - mae: 3.5099\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5159 - mae: 3.5159\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5175 - mae: 3.5175\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5069 - mae: 3.5069\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4920 - mae: 3.4920\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4704 - mae: 3.4704\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4534 - mae: 3.4534\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4483 - mae: 3.4483\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4268 - mae: 3.4268\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4194 - mae: 3.4194\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4120 - mae: 3.4120\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3956 - mae: 3.3956\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3757 - mae: 3.3757\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3477 - mae: 3.3477\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 3.3362 - mae: 3.3362\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.3275 - mae: 3.3275\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3051 - mae: 3.3051\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2856 - mae: 3.2856\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2694 - mae: 3.2694\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2465 - mae: 3.2465\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2267 - mae: 3.2267\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2103 - mae: 3.2103\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1834 - mae: 3.1834\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1620 - mae: 3.1620\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1473 - mae: 3.1473\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1263 - mae: 3.1263\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1041 - mae: 3.1041\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0863 - mae: 3.0863\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0641 - mae: 3.0641\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.0412 - mae: 3.0412\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0252 - mae: 3.0252\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9976 - mae: 2.9976\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9595 - mae: 2.9595\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9630 - mae: 2.9630\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9354 - mae: 2.9354\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8779 - mae: 2.8779\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8590 - mae: 2.8590\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8406 - mae: 2.8406\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8252 - mae: 2.8252\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7753 - mae: 2.7753\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7280 - mae: 2.7280\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6679 - mae: 2.6679\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6428 - mae: 2.6428\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6052 - mae: 2.6052\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5228 - mae: 2.5228\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.4479 - mae: 2.4479\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4003 - mae: 2.4003\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3272 - mae: 2.3272\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2284 - mae: 2.2284\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1000 - mae: 2.1000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0172 - mae: 2.0172\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9335 - mae: 1.9335\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8949 - mae: 1.8949\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7888 - mae: 1.7888\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7254 - mae: 1.7254\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6648 - mae: 1.6648\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5770 - mae: 1.5770\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4650 - mae: 1.4650\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3236 - mae: 1.3236\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1765 - mae: 1.1765\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1146 - mae: 1.1146\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9913 - mae: 0.9913\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8157 - mae: 0.8157\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7402 - mae: 0.7402\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6239 - mae: 0.6239\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5655 - mae: 0.5655\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5605 - mae: 0.5605\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5044 - mae: 0.5044\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5781 - mae: 0.5781\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4654 - mae: 0.4654\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5846 - mae: 0.5846\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4719 - mae: 0.4719\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5513 - mae: 0.5513\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5514 - mae: 0.5514\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3830 - mae: 0.3830\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5254 - mae: 0.5254\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3030 - mae: 0.3030\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6889 - mae: 0.6889\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7715 - mae: 0.7715\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3879 - mae: 0.3879\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6525 - mae: 0.6525\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8927 - mae: 0.8927\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8343 - mae: 0.8343\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4961 - mae: 0.4961\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5402 - mae: 0.5402\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7313 - mae: 0.7313\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6354 - mae: 0.6354\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3716 - mae: 0.3716\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4620 - mae: 0.4620\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6379 - mae: 0.6379\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5737 - mae: 0.5737\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3692 - mae: 0.3692\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4031 - mae: 0.4031\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4737 - mae: 0.4737\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3484 - mae: 0.3484\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2872 - mae: 0.2872\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4053 - mae: 0.4053\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3259 - mae: 0.3259\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1816 - mae: 0.1816\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2495 - mae: 0.2495\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1722 - mae: 0.1722\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1932 - mae: 0.1932\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0920 - mae: 0.0920\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2400 - mae: 0.2400\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1863 - mae: 0.1863\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1308 - mae: 0.1308\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1118 - mae: 0.1118\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2257 - mae: 0.2257\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2034 - mae: 0.2034\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1339 - mae: 0.1339\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1696 - mae: 0.1696\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2146 - mae: 0.2146\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1166 - mae: 0.1166\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2362 - mae: 0.2362\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2203 - mae: 0.2203\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1479 - mae: 0.1479\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1664 - mae: 0.1664\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1168 - mae: 0.1168\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2070 - mae: 0.2070\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2403 - mae: 0.2403\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0558 - mae: 0.0558\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0851 - mae: 0.0851\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0819 - mae: 0.0819\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0926 - mae: 0.0926\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0868 - mae: 0.0868\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0950 - mae: 0.0950\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1004 - mae: 0.1004\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1687 - mae: 0.1687\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1297 - mae: 0.1297\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0660 - mae: 0.0660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b10e43350>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets predict\n",
        "\n",
        "model.predict([25.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylEPI1yUvYST",
        "outputId": "23e0fad6-98da-4cef-ea5f-bff34c6c3436"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37.61111]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a Model\n",
        "\n",
        "In practice, a typical workflow you will go through when building a neural networks is:\n",
        "\n",
        "```\n",
        "Building a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it... and so on\n",
        "```"
      ],
      "metadata": {
        "id": "fJhhWybBw8oP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation... there are 3 words you should memorize:\n",
        "> \"Visualize, Visualize, Visualize\"\n",
        "\n",
        "It's good idea to visualize:\n",
        "* **The data** - What data are we working with? Whats does it look like?\n",
        "* **The model itself** - What dows our model look like?\n",
        "* **The training of a model** - How does a model perform while it learns?\n",
        "* **The predictions of the model** - How do the predictions of a model line up against the ground truth (the original labels)?"
      ],
      "metadata": {
        "id": "vA4tFTEiyVNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "\n",
        "X = tf.range(-100,100,4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD21LKtbzd1L",
        "outputId": "d549ed62-2a43-429f-88e0-442293260487"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFmmu6MDzxXj",
        "outputId": "afb9697d-d929-4d2b-88cb-d99bf5ea2f64"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dCodl4AN0Dku",
        "outputId": "a335c9ad-26ab-4eda-c1d2-b017a8839581"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f2b1264d090>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - The model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation Set** - The model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test Set** -  The model gest evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available.\n",
        "\n"
      ],
      "metadata": {
        "id": "laEa16cg9eRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfDawuHUAO7q",
        "outputId": "30087db4-0bee-4326-e7ee-44dd3901cb16"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splot the data into train and test sets\n",
        "\n",
        "X_train = X[:40] # First 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "\n",
        "X_test = X[40:] # The last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9HRRKYjAgDd",
        "outputId": "d03a7054-0698-4c06-f867-a062f1c00ecb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data\n",
        "Now we have got our data in training and test sets... lets visualize it again!"
      ],
      "metadata": {
        "id": "Vw8PH2s-D0xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "#Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
        "\n",
        "# Plot test data in green \n",
        "plt.scatter(X_test, y_test, c= \"g\", label=\"Testing data\")\n",
        "\n",
        "# Show legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "rSiyj_ocD2CA",
        "outputId": "e2f5781f-f1aa-47c1-d860-40e803f8607e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)                             \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "\n",
        "model.compile(loss=[\"mae\"],\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X_train, axis=-1),y_train, epochs=100)"
      ],
      "metadata": {
        "id": "FdF3ap1kFnIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the model"
      ],
      "metadata": {
        "id": "F8OCdJjKHfNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRga_QJRHiH1",
        "outputId": "b1932214-4bb1-4bb8-b8f9-564414d3a590"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a model wich builds automatically by defining the input_shape argument in the first layer\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10,input_shape=[1], name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1, name=\"output_layer\")                             \n",
        "], name=\"Model_Name\")\n",
        "\n",
        "\n",
        "# 2. Compile the model\n",
        "\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "JEP3QLrNH37K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO9zseMRJRMS",
        "outputId": "976f4764-8f9a-45e4-9c64-a8e14595f84a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_Name\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Total params** - Total number of parameters in the model.\n",
        "* **Trainablle paramters** - These are the parameters (patterns) the model can update as it trains.\n",
        "* **Non-Trainable params** _ These are the parameters are not updated during training (this is typical when you bring in alreadu learn patterns or paraemters from other models during **transfer learning**)\n",
        "\n",
        "**Resource:** For a more in-depth overview of the trainable paramters within a layer, check out MITs introduction to deep learning video."
      ],
      "metadata": {
        "id": "TtlR95iNJi7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X_train, axis=-1),y_train, epochs=100, verbose=1) #verbose is to show or not the results"
      ],
      "metadata": {
        "id": "D10wFP0YO3nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the model\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model,show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "eI-Pi04mkZUj",
        "outputId": "db79a152-a590-438f-c9c5-4705708dfd53"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Model's prediction\n",
        "\n",
        "To visualize preidctions, its a good idea to plot them against the ground truth labels. \n",
        "Often you will see this in the form of `y_test` or `y_true` versus `y_pred` (groundtruth versus model's predictions)"
      ],
      "metadata": {
        "id": "5cyOtNN2ofdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttAyh0lKpIrP",
        "outputId": "09fe28ca-819a-4277-f92b-0701a53f280f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test, X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_sf9EDDpj7P",
        "outputId": "640178e8-b004-4a2f-9dcf-0b83094d2ca0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>,\n",
              " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a plotting function\n",
        "\n",
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth lables.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  #Plot training data in blue\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",label=\"Training data\")\n",
        "\n",
        "  #Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "\n",
        "  #Plot model's predictions in red\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label = \"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend();\n",
        "\n"
      ],
      "metadata": {
        "id": "YCmDH9AoqSg1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "EtGyNHKCscn7",
        "outputId": "374903c7-70da-4940-9169-dd73ce89a539"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you're working on, there will be a different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "Since we are working on a regression, two of the main metrics:\n",
        "* **MAE** - Mean absolute error, \"on average, how wrong is each of my model's predictions\"\n",
        "* **MSE** - Mean square error, \"square the average errors\""
      ],
      "metadata": {
        "id": "LTVySgbptdk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDN9ubCovxmT",
        "outputId": "6224ad1b-8687-4d95-d550-6cf26b917fef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 328ms/step - loss: 3.1969 - mae: 3.1969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196942090988159, 3.196942090988159]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error\n",
        "\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.constant(y_pred))\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95hZvNdMwEhR",
        "outputId": "49e4050e-784b-44e0-ed76-3e44a6fd0866"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error\n",
        "\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))\n",
        "\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mURDDKIsE_eN",
        "outputId": "41df1f63-99cf-480f-cf59-9901175ba2e5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                    y_pred=tf.squeeze(y_pred))\n",
        "\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRks3EhdFhJQ",
        "outputId": "3f42425b-96bf-4812-b1bb-b442c5e1082b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some functions to reuse MAE y MSE\n",
        "def mae(y_true,y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_true,y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))"
      ],
      "metadata": {
        "id": "jbaFKphzGsX3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running experiments to improve the model\n",
        "\n",
        "1. Get more data - get more exmaples for your model to train on (more opportunities to learn patterns or relationships between features and labels)\n",
        "2. Make your model larger (using amore complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. Train for longer - give your model more of a chance to find patterns in the data.\n",
        "\n",
        "Let's do 3 experiments:\n",
        "\n",
        "1. `model_1` -  same as the original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "3. `model_3` - 2 layers, trained for 500 epochs\n",
        "\n"
      ],
      "metadata": {
        "id": "pBTBPXkPHoFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build** `model_1`"
      ],
      "metadata": {
        "id": "uxJCsN4bJ_7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)                      \n",
        "],name=\"model_1\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=[\"mae\"],\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1),y_train, epochs=100, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mivo3_4wJB9H",
        "outputId": "a06edbb1-6e85-4611-a505-f2733145dc15"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b0f411710>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "PIeog_3EYr0c",
        "outputId": "395a5e83-328e-4d25-bbcf-83f29809cc00"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2b122a73b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "\n",
        "mae_1,mse_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5bA7JyAZVr-",
        "outputId": "1a449b3b-fb1f-42e0-c672-09f9732bf025"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build** `model_2`\n",
        "\n",
        "* 2 dense layers, trained for 100 epochs"
      ],
      "metadata": {
        "id": "-dbRRV5_SZWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the random\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                               \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=[\"mae\"],\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1),y_train, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "JxK9X9W1Spc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions of model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "eSGhTQWNUWtA",
        "outputId": "9d0abf08-3119-4883-dead-e0f45698c1e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2b948eb560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 evaluation metrics\n",
        "\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test,y_preds_2)\n",
        "\n",
        "mae_2,mse_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyodDJwBU2ZW",
        "outputId": "5de27723-4560-4d5a-8acc-ef425a5d0960"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "* 2 Layers, trained for 500 epochs"
      ],
      "metadata": {
        "id": "En1WD4AyWUOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# 1. Create a model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                               \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "\n",
        "model_3.compile(loss=[\"mae\"],\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1),y_train, epochs=500, verbose=1)\n"
      ],
      "metadata": {
        "id": "4FY-E5JMWdqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot some predictions\n",
        "\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "phmIdyCEYUsO",
        "outputId": "25b17eb7-2c1b-4f60-be72-370a04962de0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate model_3 evaluation metrics\n",
        "\n",
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3 = mse(y_test, y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hih5PyQQY1FT",
        "outputId": "0fd18e0d-a1a5-41ee-a07b-09ebc21f5c92"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the results of our experiments\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ],
      "metadata": {
        "id": "M2xa74cOZYKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets compare our model's results using a pandas Dataframe\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\",mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\",mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(),mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\",\"mae\",\"mse\"])\n",
        "all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "b89vBdElaLZH",
        "outputId": "38e09c16-95fb-4f63-b0c1-c7db902276a1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-320edee2-5d92-4d00-b805-6445b19efe1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-320edee2-5d92-4d00-b805-6445b19efe1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-320edee2-5d92-4d00-b805-6445b19efe1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-320edee2-5d92-4d00-b805-6445b19efe1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like `model_2` performed the best...."
      ],
      "metadata": {
        "id": "EI3XDxzGcOsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiOmRQTycTut",
        "outputId": "0514e353-f6c6-4137-fcd0-189d88095db6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** One of your main goals should be to minimize the time between your experiments. The more expermients you do, the more things you will figure out wich out dont work and in turn, get close to figuring out what does work. Remember the machine learning praticioner's motto: \"experiment, experiment, experiment\""
      ],
      "metadata": {
        "id": "pOk0lU9JcYug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you are running a lots of expermients.\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        "**Resource:** As you build more models, you will want to look into using:\n",
        "\n",
        "* Tensorboard -ma component of the Tensorflow library to hel track modelling experiments.\n",
        "* Weights & Biases - a tool for tracking all of kinds of machine learning experiments (plus straight into TensorBoard)"
      ],
      "metadata": {
        "id": "lshI9U0ndYsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving our models\n",
        "\n",
        "There 2 fmain formats we can seva our models:\n",
        "* **The SavedModel** format\n",
        "* **The HDF5** format"
      ],
      "metadata": {
        "id": "gfWkNBxMfmBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using the SavedModel format\n",
        "\n",
        "model_2.save(\"model_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrJlJMjogRSD",
        "outputId": "0ef14ab9-341e-4d57-c5cd-8ff30f337d15"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using HDF5 format\n",
        "\n",
        "model_2.save(\"model_2.h5\")"
      ],
      "metadata": {
        "id": "pOXJ56odhUH4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in a saved model"
      ],
      "metadata": {
        "id": "V_9b4Zx94RWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the SavedModel format model\n",
        "\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"model_SavedModel_format\")\n",
        "loaded_SavedModel_format.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66lOyrbC4U1h",
        "outputId": "920a2c13-df45-470e-cf16-1b34feb8b702"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare model_2 predictions versus loaded model\n",
        "\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVovQ2O25jI8",
        "outputId": "e7911b2e-0b4e-43f7-b8b6-23ff631b6c9a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a model using the .h5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"model_2.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sK28uxo9g2e",
        "outputId": "d1c7e8b1-7db0-4988-f5f4-4b80da2429e7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "\n",
        "model_2_preds == loaded_h5_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwQTY3lG-OSm",
        "outputId": "0e8eb2e0-959f-4337-ef39-709610d8c97d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a model from Google Colab"
      ],
      "metadata": {
        "id": "_NDvF1nuC4Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download a file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/model_2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eDTrPyQ5C8ze",
        "outputId": "6f74c4b3-22b6-439c-94ac-585f319f2fc0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5aad5ad1-3d53-439f-96c9-6eb8cfd3ad21\", \"model_2.h5\", 17872)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download file to google drive\n",
        "!cp \"/content/model_2.h5\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "qCNXVJhkEEZj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Le0vLXb6EXqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A larger example"
      ],
      "metadata": {
        "id": "9MnxYVf_kvi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "JmLW0yxBk7sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reada dataset\n",
        "\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bPv185e9mBgc",
        "outputId": "f485dc4d-71bd-4424-9c25-63eb8f83f4a7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45d32adb-466c-49f3-af08-f70c67f7a06b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45d32adb-466c-49f3-af08-f70c67f7a06b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45d32adb-466c-49f3-af08-f70c67f7a06b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45d32adb-466c-49f3-af08-f70c67f7a06b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode the dataframe to have all columns in number format\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GdxcNN81mqw9",
        "outputId": "a81ccc0a-a9dc-4517-ccb3-acbed19390ee"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0   19  27.900         0  16884.92400           1         0          0   \n",
              "1   18  33.770         1   1725.55230           0         1          1   \n",
              "2   28  33.000         3   4449.46200           0         1          1   \n",
              "3   33  22.705         0  21984.47061           0         1          1   \n",
              "4   32  28.880         0   3866.85520           0         1          1   \n",
              "\n",
              "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0           1                 0                 0                 0   \n",
              "1           0                 0                 0                 1   \n",
              "2           0                 0                 0                 1   \n",
              "3           0                 0                 1                 0   \n",
              "4           0                 0                 1                 0   \n",
              "\n",
              "   region_southwest  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bb26c7d-46b4-4d93-ad2f-5024e1bebf42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bb26c7d-46b4-4d93-ad2f-5024e1bebf42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bb26c7d-46b4-4d93-ad2f-5024e1bebf42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bb26c7d-46b4-4d93-ad2f-5024e1bebf42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X, y values (features and labels)\n",
        "\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ],
      "metadata": {
        "id": "KjKaAbrhpKH4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#View X\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9-WYLtNppnaL",
        "outputId": "7331efbf-dd58-45c9-ca3a-bdb4b4f3cd76"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0   19  27.900         0           1         0          0           1   \n",
              "1   18  33.770         1           0         1          1           0   \n",
              "2   28  33.000         3           0         1          1           0   \n",
              "3   33  22.705         0           0         1          1           0   \n",
              "4   32  28.880         0           0         1          1           0   \n",
              "\n",
              "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                 0                 0                 0                 1  \n",
              "1                 0                 0                 1                 0  \n",
              "2                 0                 0                 1                 0  \n",
              "3                 0                 1                 0                 0  \n",
              "4                 0                 1                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89fdb9d1-b6c5-4419-a09d-919ab2124745\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89fdb9d1-b6c5-4419-a09d-919ab2124745')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89fdb9d1-b6c5-4419-a09d-919ab2124745 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89fdb9d1-b6c5-4419-a09d-919ab2124745');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View y\n",
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2KzWZyzpw12",
        "outputId": "63e51471-bd03-48f5-b244-bf8ada707d6b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "len(X),len(X_train),len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfE7Oc3Eqjsj",
        "outputId": "3117bc6c-b59b-49d4-d7d9-006f49751129"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                                       \n",
        "])\n",
        "\n",
        "# 2. Compile model\n",
        "insurance_model.compile(loss=[\"mae\"],\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)\n"
      ],
      "metadata": {
        "id": "Q9QRBlNcrX8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results of model on the test data\n",
        "insurance_model.evaluate(X_test,y_test) #7023.3291 representa lo distanciado que esta del valor real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUryib1NtXtp",
        "outputId": "f8b91d6a-0a5a-4c8c-ecde-65c90030ee65"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.median(), y_train.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov9jCaQ9t-ed",
        "outputId": "812d921c-f860-4340-f4b9-e3b7021c61fc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364489)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Right now it looks like our model isnt performing too well... let's try a nd improve it\n",
        "\n",
        "To try improve our model, we will run 2 experiments:\n",
        "1. Add an extra layer with more hidden units and use ADAM optimizer\n",
        "2. Train for longer\n",
        "3. (insert your own experiment here)"
      ],
      "metadata": {
        "id": "CWFHP8VCvGV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                                         \n",
        "])\n",
        "\n",
        "\n",
        "# 2.Compile the model\n",
        "insurance_model_2.compile(loss=[\"mae\"],\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)\n"
      ],
      "metadata": {
        "id": "JVMsKg5zvSJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the larger model\n",
        "\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IeZQqdzxv68",
        "outputId": "5882be71-e889-4e48-82c2-c28081afa9d7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# 1 Create the model\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)                                         \n",
        "])\n",
        "\n",
        "\n",
        "#2. Compile the model\n",
        "insurance_model_3.compile(loss=[\"mae\"],\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs=200)\n"
      ],
      "metadata": {
        "id": "wH2jvyGh1Zok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate out 3rd Model\n",
        "\n",
        "insurance_model_3.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL-9MIdg2z4X",
        "outputId": "0f572042-9229-483b-ef20-a7cbdecfefac"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "l_lCNIde3S0x",
        "outputId": "fd2ce885-9793-4e39-9377-4bf65415c669"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data (normalization and standarization)\n",
        "\n",
        "\n",
        "In terms of scalling values, neural networks tend to prefer normalization.\n",
        "\n",
        "If you are not sure on wich to use, you could try both and see wich performs better."
      ],
      "metadata": {
        "id": "A3fSRIaYM5Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TQN-kJroM-86",
        "outputId": "9d144bc5-7d8e-43ed-c0db-7d176dd02d0d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0   19  27.900         0           1         0          0           1   \n",
              "1   18  33.770         1           0         1          1           0   \n",
              "2   28  33.000         3           0         1          1           0   \n",
              "3   33  22.705         0           0         1          1           0   \n",
              "4   32  28.880         0           0         1          1           0   \n",
              "\n",
              "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                 0                 0                 0                 1  \n",
              "1                 0                 0                 1                 0  \n",
              "2                 0                 0                 1                 0  \n",
              "3                 0                 1                 0                 0  \n",
              "4                 0                 1                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d54eef25-b9eb-4aed-9509-9fb8932d828b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d54eef25-b9eb-4aed-9509-9fb8932d828b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d54eef25-b9eb-4aed-9509-9fb8932d828b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d54eef25-b9eb-4aed-9509-9fb8932d828b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"age\"].plot(kind='hist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ZXOP2BqxNw8a",
        "outputId": "b95f835c-60da-4020-a828-3c11f138082b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b10812190>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"bmi\"].plot(kind='hist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "okYzdQfUN3u2",
        "outputId": "4072bff7-8f17-43bb-a522-c602633b8038"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b10770d10>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"children\"].plot(kind='hist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "1embIQn0OCBw",
        "outputId": "21343bdc-c285-401c-d48d-bc883b2fd6b1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b10705290>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "\n",
        "\n",
        "# Read in the insurance dataframe\n",
        "\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sXqDgG-fPW6i",
        "outputId": "79062f9a-02aa-4571-ef3c-1533f1de26b8"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0295bafc-dd0f-4491-982a-d238a52adf11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0295bafc-dd0f-4491-982a-d238a52adf11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0295bafc-dd0f-4491-982a-d238a52adf11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0295bafc-dd0f-4491-982a-d238a52adf11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]), # turn all values in these columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\",\"region\"])\n",
        "\n",
        ")\n",
        "\n",
        "#Create X & y\n",
        "X =  insurance.drop(\"charges\",axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "\n",
        "# Build our train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Fit the column transformer to our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)\n"
      ],
      "metadata": {
        "id": "QkhWuQUNQuRO"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does our data look like now?\n",
        "\n",
        "X_train.loc[0], X_train_normal[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms_Z6YHcUhQb",
        "outputId": "1e86f99e-22d0-4f11-d3b4-d4642c1494c7"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(age                19\n",
              " sex            female\n",
              " bmi              27.9\n",
              " children            0\n",
              " smoker            yes\n",
              " region      southwest\n",
              " Name: 0, dtype: object,\n",
              " array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        ]))"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_train_normal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1n-4j8iVYnx",
        "outputId": "88dc6579-3324-4f3d-b55f-b71d53af95f5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our data has been normalized and one hot encoded. Now lets build a neural network model"
      ],
      "metadata": {
        "id": "NGhYdQ1FVrS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='relu'),\n",
        "  tf.keras.layers.Dense(1)                                         \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=[\"mae\"],\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"]\n",
        "                          )\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=200)"
      ],
      "metadata": {
        "id": "7jP9ShiCV1qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate insurance model\n",
        "\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqT4O30UXS4g",
        "outputId": "6658933d-a76e-4fb6-f410-d29fc17ffc89"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 2668.2688 - mae: 2668.2688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2668.268798828125, 2668.268798828125]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    }
  ]
}